{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gzip\n",
    "import gensim\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"Oct 12 2009 \\tNice trendy hotel location not too bad.\\tI stayed in this hotel for one night. As this is a fairly new place some of the taxi drivers did not know where it was and/or did not want to drive there. Once I have eventually arrived at the hotel, I was very pleasantly surprised with the decor of the lobby/ground floor area. It was very stylish and modern. I found the reception's staff geeting me with 'Aloha' a bit out of place, but I guess they are briefed to say that to keep up the coroporate image.As I have a Starwood Preferred Guest member, I was given a small gift upon-check in. It was only a couple of fridge magnets in a gift box, but nevertheless a nice gesture.My room was nice and roomy, there are tea and coffee facilities in each room and you get two complimentary bottles of water plus some toiletries by 'bliss'.The location is not great. It is at the last metro stop and you then need to take a taxi, but if you are not planning on going to see the historic sites in Beijing, then you will be ok.I chose to have some breakfast in the hotel, which was really tasty and there was a good selection of dishes. There are a couple of computers to use in the communal area, as well as a pool table. There is also a small swimming pool and a gym area.I would definitely stay in this hotel again, but only if I did not plan to travel to central Beijing, as it can take a long time. The location is ok if you plan to do a lot of shopping, as there is a big shopping centre just few minutes away from the hotel and there are plenty of eating options around, including restaurants that serve a dog meat!\\t\\r\\n\"\n",
      "\n",
      "['oct', 'nice', 'trendy', 'hotel', 'location', 'not', 'too', 'bad', 'stayed', 'in', 'this', 'hotel', 'for', 'one', 'night', 'as', 'this', 'is', 'fairly', 'new', 'place', 'some', 'of', 'the', 'taxi', 'drivers', 'did', 'not', 'know', 'where', 'it', 'was', 'and', 'or', 'did', 'not', 'want', 'to', 'drive', 'there', 'once', 'have', 'eventually', 'arrived', 'at', 'the', 'hotel', 'was', 'very', 'pleasantly', 'surprised', 'with', 'the', 'decor', 'of', 'the', 'lobby', 'ground', 'floor', 'area', 'it', 'was', 'very', 'stylish', 'and', 'modern', 'found', 'the', 'reception', 'staff', 'geeting', 'me', 'with', 'aloha', 'bit', 'out', 'of', 'place', 'but', 'guess', 'they', 'are', 'briefed', 'to', 'say', 'that', 'to', 'keep', 'up', 'the', 'coroporate', 'image', 'as', 'have', 'starwood', 'preferred', 'guest', 'member', 'was', 'given', 'small', 'gift', 'upon', 'check', 'in', 'it', 'was', 'only', 'couple', 'of', 'fridge', 'magnets', 'in', 'gift', 'box', 'but', 'nevertheless', 'nice', 'gesture', 'my', 'room', 'was', 'nice', 'and', 'roomy', 'there', 'are', 'tea', 'and', 'coffee', 'facilities', 'in', 'each', 'room', 'and', 'you', 'get', 'two', 'complimentary', 'bottles', 'of', 'water', 'plus', 'some', 'toiletries', 'by', 'bliss', 'the', 'location', 'is', 'not', 'great', 'it', 'is', 'at', 'the', 'last', 'metro', 'stop', 'and', 'you', 'then', 'need', 'to', 'take', 'taxi', 'but', 'if', 'you', 'are', 'not', 'planning', 'on', 'going', 'to', 'see', 'the', 'historic', 'sites', 'in', 'beijing', 'then', 'you', 'will', 'be', 'ok', 'chose', 'to', 'have', 'some', 'breakfast', 'in', 'the', 'hotel', 'which', 'was', 'really', 'tasty', 'and', 'there', 'was', 'good', 'selection', 'of', 'dishes', 'there', 'are', 'couple', 'of', 'computers', 'to', 'use', 'in', 'the', 'communal', 'area', 'as', 'well', 'as', 'pool', 'table', 'there', 'is', 'also', 'small', 'swimming', 'pool', 'and', 'gym', 'area', 'would', 'definitely', 'stay', 'in', 'this', 'hotel', 'again', 'but', 'only', 'if', 'did', 'not', 'plan', 'to', 'travel', 'to', 'central', 'beijing', 'as', 'it', 'can', 'take', 'long', 'time', 'the', 'location', 'is', 'ok', 'if', 'you', 'plan', 'to', 'do', 'lot', 'of', 'shopping', 'as', 'there', 'is', 'big', 'shopping', 'centre', 'just', 'few', 'minutes', 'away', 'from', 'the', 'hotel', 'and', 'there', 'are', 'plenty', 'of', 'eating', 'options', 'around', 'including', 'restaurants', 'that', 'serve', 'dog', 'meat']\n"
     ]
    }
   ],
   "source": [
    "input_file = 'reviews_data.txt.gz'\n",
    "with gzip.open(input_file, 'rb') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        print(line)\n",
    "        print()\n",
    "        print(gensim.utils.simple_preprocess(line))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_input(input_file):\n",
    "    logging.info(\"reading file {0}...this may take a while\".format(input_file))\n",
    "    with gzip.open(input_file, 'rb') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if (i % 10000 == 0):\n",
    "                logging.info(\"read {0} reviews\".format(i))\n",
    "            yield gensim.utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-04 14:36:54,096 : INFO : reading file reviews_data.txt.gz...this may take a while\n",
      "2018-09-04 14:36:54,099 : INFO : read 0 reviews\n",
      "2018-09-04 14:36:57,748 : INFO : read 10000 reviews\n",
      "2018-09-04 14:37:01,034 : INFO : read 20000 reviews\n",
      "2018-09-04 14:37:05,054 : INFO : read 30000 reviews\n",
      "2018-09-04 14:37:08,800 : INFO : read 40000 reviews\n",
      "2018-09-04 14:37:13,245 : INFO : read 50000 reviews\n",
      "2018-09-04 14:37:17,080 : INFO : read 60000 reviews\n",
      "2018-09-04 14:37:20,291 : INFO : read 70000 reviews\n",
      "2018-09-04 14:37:23,638 : INFO : read 80000 reviews\n",
      "2018-09-04 14:37:26,822 : INFO : read 90000 reviews\n",
      "2018-09-04 14:37:30,089 : INFO : read 100000 reviews\n",
      "2018-09-04 14:37:33,180 : INFO : read 110000 reviews\n",
      "2018-09-04 14:37:36,320 : INFO : read 120000 reviews\n",
      "2018-09-04 14:37:39,311 : INFO : read 130000 reviews\n",
      "2018-09-04 14:37:42,614 : INFO : read 140000 reviews\n",
      "2018-09-04 14:37:45,616 : INFO : read 150000 reviews\n",
      "2018-09-04 14:37:48,734 : INFO : read 160000 reviews\n",
      "2018-09-04 14:37:52,568 : INFO : read 170000 reviews\n",
      "2018-09-04 14:37:55,830 : INFO : read 180000 reviews\n",
      "2018-09-04 14:37:59,152 : INFO : read 190000 reviews\n",
      "2018-09-04 14:38:02,515 : INFO : read 200000 reviews\n",
      "2018-09-04 14:38:05,744 : INFO : read 210000 reviews\n",
      "2018-09-04 14:38:09,137 : INFO : read 220000 reviews\n",
      "2018-09-04 14:38:12,268 : INFO : read 230000 reviews\n",
      "2018-09-04 14:38:15,383 : INFO : read 240000 reviews\n",
      "2018-09-04 14:38:18,402 : INFO : read 250000 reviews\n",
      "2018-09-04 14:38:20,057 : INFO : Done reading data file\n"
     ]
    }
   ],
   "source": [
    "## word2vec model expects a list of tokenized sentences \n",
    "## sentences with 2 and 3 words: [['word1', 'word2'], ['word3', 'word4', 'word5']]\n",
    "\n",
    "# read the tokenized reviews into a list each review item becomes a serries of words\n",
    "# so this becomes a list of lists\n",
    "documents = list(read_input(input_file))\n",
    "logging.info(\"Done reading data file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-04 14:45:49,963 : INFO : collecting all words and their counts\n",
      "2018-09-04 14:45:49,965 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-09-04 14:45:50,322 : INFO : PROGRESS: at sentence #10000, processed 1655714 words, keeping 25777 word types\n",
      "2018-09-04 14:45:50,703 : INFO : PROGRESS: at sentence #20000, processed 3317863 words, keeping 35016 word types\n",
      "2018-09-04 14:45:51,154 : INFO : PROGRESS: at sentence #30000, processed 5264072 words, keeping 47518 word types\n",
      "2018-09-04 14:45:51,566 : INFO : PROGRESS: at sentence #40000, processed 7081746 words, keeping 56675 word types\n",
      "2018-09-04 14:45:52,023 : INFO : PROGRESS: at sentence #50000, processed 9089491 words, keeping 63744 word types\n",
      "2018-09-04 14:45:52,508 : INFO : PROGRESS: at sentence #60000, processed 11013723 words, keeping 76781 word types\n",
      "2018-09-04 14:45:52,886 : INFO : PROGRESS: at sentence #70000, processed 12637525 words, keeping 83194 word types\n",
      "2018-09-04 14:45:53,231 : INFO : PROGRESS: at sentence #80000, processed 14099751 words, keeping 88454 word types\n",
      "2018-09-04 14:45:53,607 : INFO : PROGRESS: at sentence #90000, processed 15662149 words, keeping 93352 word types\n",
      "2018-09-04 14:45:53,960 : INFO : PROGRESS: at sentence #100000, processed 17164487 words, keeping 97881 word types\n",
      "2018-09-04 14:45:54,310 : INFO : PROGRESS: at sentence #110000, processed 18652292 words, keeping 102127 word types\n",
      "2018-09-04 14:45:54,654 : INFO : PROGRESS: at sentence #120000, processed 20152529 words, keeping 105918 word types\n",
      "2018-09-04 14:45:55,019 : INFO : PROGRESS: at sentence #130000, processed 21684330 words, keeping 110099 word types\n",
      "2018-09-04 14:45:55,425 : INFO : PROGRESS: at sentence #140000, processed 23330206 words, keeping 114103 word types\n",
      "2018-09-04 14:45:55,769 : INFO : PROGRESS: at sentence #150000, processed 24838754 words, keeping 118169 word types\n",
      "2018-09-04 14:45:56,124 : INFO : PROGRESS: at sentence #160000, processed 26390910 words, keeping 118665 word types\n",
      "2018-09-04 14:45:56,477 : INFO : PROGRESS: at sentence #170000, processed 27913916 words, keeping 123350 word types\n",
      "2018-09-04 14:45:56,846 : INFO : PROGRESS: at sentence #180000, processed 29535612 words, keeping 126742 word types\n",
      "2018-09-04 14:45:57,235 : INFO : PROGRESS: at sentence #190000, processed 31096459 words, keeping 129841 word types\n",
      "2018-09-04 14:45:57,627 : INFO : PROGRESS: at sentence #200000, processed 32805271 words, keeping 133249 word types\n",
      "2018-09-04 14:45:58,024 : INFO : PROGRESS: at sentence #210000, processed 34434198 words, keeping 136358 word types\n",
      "2018-09-04 14:45:58,453 : INFO : PROGRESS: at sentence #220000, processed 36083482 words, keeping 139412 word types\n",
      "2018-09-04 14:45:58,804 : INFO : PROGRESS: at sentence #230000, processed 37571762 words, keeping 142393 word types\n",
      "2018-09-04 14:45:59,172 : INFO : PROGRESS: at sentence #240000, processed 39138190 words, keeping 145226 word types\n",
      "2018-09-04 14:45:59,547 : INFO : PROGRESS: at sentence #250000, processed 40695049 words, keeping 147960 word types\n",
      "2018-09-04 14:45:59,751 : INFO : collected 150053 word types from a corpus of 41519355 raw words and 255404 sentences\n",
      "2018-09-04 14:45:59,752 : INFO : Loading a fresh vocabulary\n",
      "2018-09-04 14:46:00,865 : INFO : min_count=2 retains 70538 unique words (47% of original 150053, drops 79515)\n",
      "2018-09-04 14:46:00,866 : INFO : min_count=2 leaves 41439840 word corpus (99% of original 41519355, drops 79515)\n",
      "2018-09-04 14:46:01,119 : INFO : deleting the raw counts dictionary of 150053 items\n",
      "2018-09-04 14:46:01,125 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2018-09-04 14:46:01,126 : INFO : downsampling leaves estimated 30349255 word corpus (73.2% of prior 41439840)\n",
      "2018-09-04 14:46:01,460 : INFO : estimated required memory for 70538 words and 128 dimensions: 107499912 bytes\n",
      "2018-09-04 14:46:01,462 : INFO : resetting layer weights\n",
      "2018-09-04 14:46:02,578 : INFO : training model with 10 workers on 70538 vocabulary and 128 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-09-04 14:46:03,588 : INFO : EPOCH 1 - PROGRESS: at 1.48% examples, 469955 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:46:04,614 : INFO : EPOCH 1 - PROGRESS: at 3.46% examples, 530056 words/s, in_qsize 20, out_qsize 1\n",
      "2018-09-04 14:46:05,617 : INFO : EPOCH 1 - PROGRESS: at 5.46% examples, 554259 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:46:06,652 : INFO : EPOCH 1 - PROGRESS: at 7.19% examples, 544003 words/s, in_qsize 10, out_qsize 9\n",
      "2018-09-04 14:46:07,670 : INFO : EPOCH 1 - PROGRESS: at 9.19% examples, 562290 words/s, in_qsize 20, out_qsize 3\n",
      "2018-09-04 14:46:08,674 : INFO : EPOCH 1 - PROGRESS: at 10.67% examples, 561874 words/s, in_qsize 17, out_qsize 2\n",
      "2018-09-04 14:46:09,691 : INFO : EPOCH 1 - PROGRESS: at 12.15% examples, 562224 words/s, in_qsize 19, out_qsize 3\n",
      "2018-09-04 14:46:10,693 : INFO : EPOCH 1 - PROGRESS: at 13.79% examples, 561237 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:46:11,705 : INFO : EPOCH 1 - PROGRESS: at 15.49% examples, 562199 words/s, in_qsize 18, out_qsize 5\n",
      "2018-09-04 14:46:12,739 : INFO : EPOCH 1 - PROGRESS: at 17.14% examples, 563900 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:46:13,740 : INFO : EPOCH 1 - PROGRESS: at 18.80% examples, 568043 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:46:14,797 : INFO : EPOCH 1 - PROGRESS: at 20.17% examples, 563402 words/s, in_qsize 17, out_qsize 4\n",
      "2018-09-04 14:46:15,811 : INFO : EPOCH 1 - PROGRESS: at 21.86% examples, 560779 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:46:16,823 : INFO : EPOCH 1 - PROGRESS: at 23.18% examples, 557369 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:46:17,878 : INFO : EPOCH 1 - PROGRESS: at 24.40% examples, 551005 words/s, in_qsize 19, out_qsize 7\n",
      "2018-09-04 14:46:18,848 : INFO : EPOCH 1 - PROGRESS: at 26.16% examples, 547225 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:46:19,854 : INFO : EPOCH 1 - PROGRESS: at 28.03% examples, 543784 words/s, in_qsize 12, out_qsize 2\n",
      "2018-09-04 14:46:20,884 : INFO : EPOCH 1 - PROGRESS: at 29.90% examples, 542320 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:46:21,888 : INFO : EPOCH 1 - PROGRESS: at 31.92% examples, 542568 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:46:22,899 : INFO : EPOCH 1 - PROGRESS: at 33.75% examples, 542514 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:46:23,951 : INFO : EPOCH 1 - PROGRESS: at 35.75% examples, 542587 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:46:24,980 : INFO : EPOCH 1 - PROGRESS: at 37.48% examples, 539849 words/s, in_qsize 19, out_qsize 1\n",
      "2018-09-04 14:46:25,985 : INFO : EPOCH 1 - PROGRESS: at 39.43% examples, 539735 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:46:27,007 : INFO : EPOCH 1 - PROGRESS: at 41.23% examples, 537222 words/s, in_qsize 19, out_qsize 3\n",
      "2018-09-04 14:46:28,009 : INFO : EPOCH 1 - PROGRESS: at 42.96% examples, 535280 words/s, in_qsize 15, out_qsize 4\n",
      "2018-09-04 14:46:29,033 : INFO : EPOCH 1 - PROGRESS: at 44.89% examples, 533913 words/s, in_qsize 20, out_qsize 1\n",
      "2018-09-04 14:46:30,037 : INFO : EPOCH 1 - PROGRESS: at 46.46% examples, 530666 words/s, in_qsize 20, out_qsize 6\n",
      "2018-09-04 14:46:31,062 : INFO : EPOCH 1 - PROGRESS: at 48.38% examples, 531492 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:46:32,071 : INFO : EPOCH 1 - PROGRESS: at 50.13% examples, 529935 words/s, in_qsize 20, out_qsize 2\n",
      "2018-09-04 14:46:33,073 : INFO : EPOCH 1 - PROGRESS: at 51.85% examples, 529232 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:46:34,079 : INFO : EPOCH 1 - PROGRESS: at 53.66% examples, 530380 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:46:35,081 : INFO : EPOCH 1 - PROGRESS: at 55.52% examples, 529842 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:46:36,094 : INFO : EPOCH 1 - PROGRESS: at 57.31% examples, 529361 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:46:37,130 : INFO : EPOCH 1 - PROGRESS: at 58.95% examples, 527253 words/s, in_qsize 14, out_qsize 5\n",
      "2018-09-04 14:46:38,150 : INFO : EPOCH 1 - PROGRESS: at 60.94% examples, 528454 words/s, in_qsize 18, out_qsize 2\n",
      "2018-09-04 14:46:39,184 : INFO : EPOCH 1 - PROGRESS: at 62.63% examples, 526936 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:46:40,192 : INFO : EPOCH 1 - PROGRESS: at 64.49% examples, 525697 words/s, in_qsize 19, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-04 14:46:41,218 : INFO : EPOCH 1 - PROGRESS: at 66.22% examples, 525669 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:46:42,227 : INFO : EPOCH 1 - PROGRESS: at 68.06% examples, 525702 words/s, in_qsize 16, out_qsize 3\n",
      "2018-09-04 14:46:43,293 : INFO : EPOCH 1 - PROGRESS: at 69.79% examples, 525009 words/s, in_qsize 17, out_qsize 2\n",
      "2018-09-04 14:46:44,300 : INFO : EPOCH 1 - PROGRESS: at 71.81% examples, 527557 words/s, in_qsize 20, out_qsize 4\n",
      "2018-09-04 14:46:45,327 : INFO : EPOCH 1 - PROGRESS: at 73.77% examples, 527349 words/s, in_qsize 20, out_qsize 3\n",
      "2018-09-04 14:46:46,390 : INFO : EPOCH 1 - PROGRESS: at 75.58% examples, 527571 words/s, in_qsize 19, out_qsize 1\n",
      "2018-09-04 14:46:47,397 : INFO : EPOCH 1 - PROGRESS: at 77.19% examples, 527278 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:46:48,442 : INFO : EPOCH 1 - PROGRESS: at 78.81% examples, 526380 words/s, in_qsize 19, out_qsize 4\n",
      "2018-09-04 14:46:49,442 : INFO : EPOCH 1 - PROGRESS: at 80.62% examples, 526994 words/s, in_qsize 19, out_qsize 1\n",
      "2018-09-04 14:46:50,464 : INFO : EPOCH 1 - PROGRESS: at 82.64% examples, 528234 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:46:51,490 : INFO : EPOCH 1 - PROGRESS: at 84.47% examples, 528906 words/s, in_qsize 20, out_qsize 3\n",
      "2018-09-04 14:46:52,508 : INFO : EPOCH 1 - PROGRESS: at 86.54% examples, 530509 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:46:53,509 : INFO : EPOCH 1 - PROGRESS: at 88.77% examples, 531994 words/s, in_qsize 17, out_qsize 2\n",
      "2018-09-04 14:46:54,519 : INFO : EPOCH 1 - PROGRESS: at 90.80% examples, 532779 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:46:55,523 : INFO : EPOCH 1 - PROGRESS: at 92.71% examples, 533289 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:46:56,525 : INFO : EPOCH 1 - PROGRESS: at 94.55% examples, 533418 words/s, in_qsize 20, out_qsize 2\n",
      "2018-09-04 14:46:57,574 : INFO : EPOCH 1 - PROGRESS: at 96.73% examples, 534779 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:46:58,596 : INFO : EPOCH 1 - PROGRESS: at 98.77% examples, 535554 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:46:59,013 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-09-04 14:46:59,023 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-09-04 14:46:59,029 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-09-04 14:46:59,043 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-09-04 14:46:59,055 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 14:46:59,058 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 14:46:59,059 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 14:46:59,062 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 14:46:59,070 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 14:46:59,074 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 14:46:59,075 : INFO : EPOCH - 1 : training on 41519355 raw words (30346223 effective words) took 56.5s, 537213 effective words/s\n",
      "2018-09-04 14:47:00,102 : INFO : EPOCH 2 - PROGRESS: at 1.54% examples, 476122 words/s, in_qsize 20, out_qsize 1\n",
      "2018-09-04 14:47:01,106 : INFO : EPOCH 2 - PROGRESS: at 3.60% examples, 552633 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:02,109 : INFO : EPOCH 2 - PROGRESS: at 5.29% examples, 538821 words/s, in_qsize 20, out_qsize 2\n",
      "2018-09-04 14:47:03,118 : INFO : EPOCH 2 - PROGRESS: at 6.94% examples, 528984 words/s, in_qsize 20, out_qsize 1\n",
      "2018-09-04 14:47:04,186 : INFO : EPOCH 2 - PROGRESS: at 8.48% examples, 514118 words/s, in_qsize 13, out_qsize 6\n",
      "2018-09-04 14:47:05,207 : INFO : EPOCH 2 - PROGRESS: at 10.07% examples, 523408 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:47:06,272 : INFO : EPOCH 2 - PROGRESS: at 11.53% examples, 520887 words/s, in_qsize 19, out_qsize 2\n",
      "2018-09-04 14:47:07,293 : INFO : EPOCH 2 - PROGRESS: at 13.08% examples, 525309 words/s, in_qsize 18, out_qsize 0\n",
      "2018-09-04 14:47:08,305 : INFO : EPOCH 2 - PROGRESS: at 14.72% examples, 527726 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:09,329 : INFO : EPOCH 2 - PROGRESS: at 16.37% examples, 531343 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:10,344 : INFO : EPOCH 2 - PROGRESS: at 17.80% examples, 530921 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:11,382 : INFO : EPOCH 2 - PROGRESS: at 19.18% examples, 527368 words/s, in_qsize 18, out_qsize 5\n",
      "2018-09-04 14:47:12,382 : INFO : EPOCH 2 - PROGRESS: at 20.54% examples, 528216 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:47:13,385 : INFO : EPOCH 2 - PROGRESS: at 22.21% examples, 527724 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:47:14,411 : INFO : EPOCH 2 - PROGRESS: at 23.56% examples, 527131 words/s, in_qsize 18, out_qsize 0\n",
      "2018-09-04 14:47:15,465 : INFO : EPOCH 2 - PROGRESS: at 24.75% examples, 520412 words/s, in_qsize 20, out_qsize 3\n",
      "2018-09-04 14:47:16,496 : INFO : EPOCH 2 - PROGRESS: at 26.65% examples, 518635 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:17,521 : INFO : EPOCH 2 - PROGRESS: at 28.22% examples, 512927 words/s, in_qsize 19, out_qsize 4\n",
      "2018-09-04 14:47:18,530 : INFO : EPOCH 2 - PROGRESS: at 29.78% examples, 508521 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:19,558 : INFO : EPOCH 2 - PROGRESS: at 31.76% examples, 509118 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:20,561 : INFO : EPOCH 2 - PROGRESS: at 33.48% examples, 508820 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:21,566 : INFO : EPOCH 2 - PROGRESS: at 34.88% examples, 504764 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:47:22,611 : INFO : EPOCH 2 - PROGRESS: at 36.62% examples, 503596 words/s, in_qsize 18, out_qsize 5\n",
      "2018-09-04 14:47:23,589 : INFO : EPOCH 2 - PROGRESS: at 38.37% examples, 503040 words/s, in_qsize 13, out_qsize 9\n",
      "2018-09-04 14:47:24,597 : INFO : EPOCH 2 - PROGRESS: at 40.29% examples, 504673 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:47:25,608 : INFO : EPOCH 2 - PROGRESS: at 41.97% examples, 502008 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:26,664 : INFO : EPOCH 2 - PROGRESS: at 43.50% examples, 498728 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:27,674 : INFO : EPOCH 2 - PROGRESS: at 45.26% examples, 497750 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:28,697 : INFO : EPOCH 2 - PROGRESS: at 46.83% examples, 495863 words/s, in_qsize 19, out_qsize 2\n",
      "2018-09-04 14:47:29,717 : INFO : EPOCH 2 - PROGRESS: at 48.62% examples, 496334 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:30,741 : INFO : EPOCH 2 - PROGRESS: at 50.39% examples, 496175 words/s, in_qsize 20, out_qsize 4\n",
      "2018-09-04 14:47:31,793 : INFO : EPOCH 2 - PROGRESS: at 52.24% examples, 497133 words/s, in_qsize 18, out_qsize 2\n",
      "2018-09-04 14:47:32,809 : INFO : EPOCH 2 - PROGRESS: at 53.91% examples, 497536 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:47:33,819 : INFO : EPOCH 2 - PROGRESS: at 55.79% examples, 498064 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:34,845 : INFO : EPOCH 2 - PROGRESS: at 57.49% examples, 497546 words/s, in_qsize 18, out_qsize 3\n",
      "2018-09-04 14:47:35,848 : INFO : EPOCH 2 - PROGRESS: at 59.20% examples, 497716 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:36,865 : INFO : EPOCH 2 - PROGRESS: at 60.71% examples, 495658 words/s, in_qsize 19, out_qsize 6\n",
      "2018-09-04 14:47:37,915 : INFO : EPOCH 2 - PROGRESS: at 62.37% examples, 494933 words/s, in_qsize 20, out_qsize 3\n",
      "2018-09-04 14:47:38,919 : INFO : EPOCH 2 - PROGRESS: at 64.22% examples, 494593 words/s, in_qsize 20, out_qsize 1\n",
      "2018-09-04 14:47:39,937 : INFO : EPOCH 2 - PROGRESS: at 65.98% examples, 495477 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:40,966 : INFO : EPOCH 2 - PROGRESS: at 67.91% examples, 496643 words/s, in_qsize 16, out_qsize 3\n",
      "2018-09-04 14:47:41,984 : INFO : EPOCH 2 - PROGRESS: at 69.61% examples, 497088 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:43,029 : INFO : EPOCH 2 - PROGRESS: at 71.46% examples, 498245 words/s, in_qsize 16, out_qsize 3\n",
      "2018-09-04 14:47:44,039 : INFO : EPOCH 2 - PROGRESS: at 73.64% examples, 500666 words/s, in_qsize 19, out_qsize 1\n",
      "2018-09-04 14:47:45,110 : INFO : EPOCH 2 - PROGRESS: at 75.56% examples, 502014 words/s, in_qsize 16, out_qsize 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-04 14:47:46,144 : INFO : EPOCH 2 - PROGRESS: at 77.41% examples, 503662 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:47,146 : INFO : EPOCH 2 - PROGRESS: at 79.20% examples, 504679 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:48,160 : INFO : EPOCH 2 - PROGRESS: at 81.11% examples, 506431 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:47:49,188 : INFO : EPOCH 2 - PROGRESS: at 82.98% examples, 506833 words/s, in_qsize 17, out_qsize 2\n",
      "2018-09-04 14:47:50,204 : INFO : EPOCH 2 - PROGRESS: at 84.90% examples, 508706 words/s, in_qsize 17, out_qsize 2\n",
      "2018-09-04 14:47:51,231 : INFO : EPOCH 2 - PROGRESS: at 86.85% examples, 509578 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:52,261 : INFO : EPOCH 2 - PROGRESS: at 88.61% examples, 508677 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:47:53,275 : INFO : EPOCH 2 - PROGRESS: at 90.40% examples, 508642 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:54,284 : INFO : EPOCH 2 - PROGRESS: at 92.31% examples, 509159 words/s, in_qsize 19, out_qsize 2\n",
      "2018-09-04 14:47:55,288 : INFO : EPOCH 2 - PROGRESS: at 94.07% examples, 509436 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:56,314 : INFO : EPOCH 2 - PROGRESS: at 95.84% examples, 509389 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:47:57,352 : INFO : EPOCH 2 - PROGRESS: at 97.85% examples, 510430 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:47:58,368 : INFO : EPOCH 2 - PROGRESS: at 99.57% examples, 509986 words/s, in_qsize 15, out_qsize 2\n",
      "2018-09-04 14:47:58,404 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-09-04 14:47:58,443 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-09-04 14:47:58,443 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-09-04 14:47:58,444 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-09-04 14:47:58,445 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 14:47:58,456 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 14:47:58,468 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 14:47:58,479 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 14:47:58,484 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 14:47:58,509 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 14:47:58,511 : INFO : EPOCH - 2 : training on 41519355 raw words (30353594 effective words) took 59.4s, 510765 effective words/s\n",
      "2018-09-04 14:47:59,546 : INFO : EPOCH 3 - PROGRESS: at 1.55% examples, 479504 words/s, in_qsize 19, out_qsize 1\n",
      "2018-09-04 14:48:00,590 : INFO : EPOCH 3 - PROGRESS: at 3.39% examples, 508792 words/s, in_qsize 18, out_qsize 3\n",
      "2018-09-04 14:48:01,609 : INFO : EPOCH 3 - PROGRESS: at 5.08% examples, 506976 words/s, in_qsize 18, out_qsize 4\n",
      "2018-09-04 14:48:02,627 : INFO : EPOCH 3 - PROGRESS: at 6.74% examples, 505541 words/s, in_qsize 20, out_qsize 1\n",
      "2018-09-04 14:48:03,666 : INFO : EPOCH 3 - PROGRESS: at 8.20% examples, 494286 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:48:04,710 : INFO : EPOCH 3 - PROGRESS: at 9.65% examples, 490976 words/s, in_qsize 19, out_qsize 2\n",
      "2018-09-04 14:48:05,725 : INFO : EPOCH 3 - PROGRESS: at 11.10% examples, 498689 words/s, in_qsize 20, out_qsize 1\n",
      "2018-09-04 14:48:06,769 : INFO : EPOCH 3 - PROGRESS: at 12.63% examples, 508158 words/s, in_qsize 17, out_qsize 5\n",
      "2018-09-04 14:48:07,746 : INFO : EPOCH 3 - PROGRESS: at 14.36% examples, 514960 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:48:08,760 : INFO : EPOCH 3 - PROGRESS: at 16.03% examples, 519019 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:48:09,773 : INFO : EPOCH 3 - PROGRESS: at 17.55% examples, 523498 words/s, in_qsize 19, out_qsize 1\n",
      "2018-09-04 14:48:10,783 : INFO : EPOCH 3 - PROGRESS: at 18.81% examples, 516625 words/s, in_qsize 20, out_qsize 2\n",
      "2018-09-04 14:48:11,807 : INFO : EPOCH 3 - PROGRESS: at 19.96% examples, 511261 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:48:12,916 : INFO : EPOCH 3 - PROGRESS: at 20.98% examples, 500534 words/s, in_qsize 20, out_qsize 4\n",
      "2018-09-04 14:48:13,929 : INFO : EPOCH 3 - PROGRESS: at 22.72% examples, 502329 words/s, in_qsize 20, out_qsize 1\n",
      "2018-09-04 14:48:14,964 : INFO : EPOCH 3 - PROGRESS: at 23.83% examples, 497809 words/s, in_qsize 17, out_qsize 2\n",
      "2018-09-04 14:48:15,968 : INFO : EPOCH 3 - PROGRESS: at 25.55% examples, 500475 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:48:16,984 : INFO : EPOCH 3 - PROGRESS: at 27.11% examples, 495685 words/s, in_qsize 20, out_qsize 5\n",
      "2018-09-04 14:48:18,037 : INFO : EPOCH 3 - PROGRESS: at 29.04% examples, 495928 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:48:19,091 : INFO : EPOCH 3 - PROGRESS: at 30.82% examples, 495088 words/s, in_qsize 20, out_qsize 7\n",
      "2018-09-04 14:48:20,113 : INFO : EPOCH 3 - PROGRESS: at 33.07% examples, 499969 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:48:21,127 : INFO : EPOCH 3 - PROGRESS: at 34.65% examples, 498693 words/s, in_qsize 18, out_qsize 6\n",
      "2018-09-04 14:48:22,133 : INFO : EPOCH 3 - PROGRESS: at 36.27% examples, 496996 words/s, in_qsize 15, out_qsize 4\n",
      "2018-09-04 14:48:23,148 : INFO : EPOCH 3 - PROGRESS: at 38.15% examples, 498431 words/s, in_qsize 16, out_qsize 3\n",
      "2018-09-04 14:48:24,163 : INFO : EPOCH 3 - PROGRESS: at 39.79% examples, 497004 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:48:25,169 : INFO : EPOCH 3 - PROGRESS: at 41.71% examples, 496929 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:48:26,206 : INFO : EPOCH 3 - PROGRESS: at 43.31% examples, 494946 words/s, in_qsize 18, out_qsize 5\n",
      "2018-09-04 14:48:27,213 : INFO : EPOCH 3 - PROGRESS: at 45.26% examples, 495677 words/s, in_qsize 15, out_qsize 1\n",
      "2018-09-04 14:48:28,233 : INFO : EPOCH 3 - PROGRESS: at 46.91% examples, 495110 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:48:29,293 : INFO : EPOCH 3 - PROGRESS: at 48.49% examples, 492845 words/s, in_qsize 20, out_qsize 4\n",
      "2018-09-04 14:48:30,309 : INFO : EPOCH 3 - PROGRESS: at 50.25% examples, 492717 words/s, in_qsize 16, out_qsize 3\n",
      "2018-09-04 14:48:31,311 : INFO : EPOCH 3 - PROGRESS: at 52.04% examples, 493874 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:48:32,327 : INFO : EPOCH 3 - PROGRESS: at 53.37% examples, 491601 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:48:33,337 : INFO : EPOCH 3 - PROGRESS: at 54.92% examples, 490444 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:48:34,348 : INFO : EPOCH 3 - PROGRESS: at 56.90% examples, 491950 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:48:35,427 : INFO : EPOCH 3 - PROGRESS: at 58.44% examples, 489887 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:48:36,459 : INFO : EPOCH 3 - PROGRESS: at 60.02% examples, 488580 words/s, in_qsize 20, out_qsize 1\n",
      "2018-09-04 14:48:37,466 : INFO : EPOCH 3 - PROGRESS: at 61.71% examples, 488602 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:48:38,517 : INFO : EPOCH 3 - PROGRESS: at 63.61% examples, 488759 words/s, in_qsize 18, out_qsize 3\n",
      "2018-09-04 14:48:39,518 : INFO : EPOCH 3 - PROGRESS: at 65.62% examples, 490862 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:48:40,557 : INFO : EPOCH 3 - PROGRESS: at 67.40% examples, 491345 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:48:41,573 : INFO : EPOCH 3 - PROGRESS: at 69.24% examples, 492469 words/s, in_qsize 20, out_qsize 3\n",
      "2018-09-04 14:48:42,589 : INFO : EPOCH 3 - PROGRESS: at 71.02% examples, 494025 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:48:43,611 : INFO : EPOCH 3 - PROGRESS: at 73.08% examples, 495774 words/s, in_qsize 20, out_qsize 1\n",
      "2018-09-04 14:48:44,629 : INFO : EPOCH 3 - PROGRESS: at 75.02% examples, 497290 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:48:45,635 : INFO : EPOCH 3 - PROGRESS: at 76.54% examples, 497229 words/s, in_qsize 20, out_qsize 2\n",
      "2018-09-04 14:48:46,652 : INFO : EPOCH 3 - PROGRESS: at 78.58% examples, 500043 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:48:47,653 : INFO : EPOCH 3 - PROGRESS: at 80.40% examples, 501147 words/s, in_qsize 17, out_qsize 2\n",
      "2018-09-04 14:48:48,689 : INFO : EPOCH 3 - PROGRESS: at 82.20% examples, 501688 words/s, in_qsize 19, out_qsize 5\n",
      "2018-09-04 14:48:49,767 : INFO : EPOCH 3 - PROGRESS: at 84.07% examples, 502100 words/s, in_qsize 18, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-04 14:48:50,783 : INFO : EPOCH 3 - PROGRESS: at 85.82% examples, 502779 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:48:51,800 : INFO : EPOCH 3 - PROGRESS: at 87.91% examples, 504019 words/s, in_qsize 18, out_qsize 5\n",
      "2018-09-04 14:48:52,801 : INFO : EPOCH 3 - PROGRESS: at 89.68% examples, 504031 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:48:53,829 : INFO : EPOCH 3 - PROGRESS: at 91.45% examples, 503804 words/s, in_qsize 20, out_qsize 5\n",
      "2018-09-04 14:48:54,862 : INFO : EPOCH 3 - PROGRESS: at 93.39% examples, 504804 words/s, in_qsize 20, out_qsize 1\n",
      "2018-09-04 14:48:55,865 : INFO : EPOCH 3 - PROGRESS: at 95.46% examples, 506311 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:48:56,869 : INFO : EPOCH 3 - PROGRESS: at 97.48% examples, 507606 words/s, in_qsize 20, out_qsize 1\n",
      "2018-09-04 14:48:57,875 : INFO : EPOCH 3 - PROGRESS: at 99.17% examples, 507389 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:48:58,176 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-09-04 14:48:58,195 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-09-04 14:48:58,214 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-09-04 14:48:58,234 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-09-04 14:48:58,236 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 14:48:58,236 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 14:48:58,237 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 14:48:58,258 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 14:48:58,260 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 14:48:58,261 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 14:48:58,262 : INFO : EPOCH - 3 : training on 41519355 raw words (30350918 effective words) took 59.7s, 508017 effective words/s\n",
      "2018-09-04 14:48:59,350 : INFO : EPOCH 4 - PROGRESS: at 1.76% examples, 549232 words/s, in_qsize 20, out_qsize 2\n",
      "2018-09-04 14:49:00,377 : INFO : EPOCH 4 - PROGRESS: at 3.47% examples, 527193 words/s, in_qsize 15, out_qsize 3\n",
      "2018-09-04 14:49:01,390 : INFO : EPOCH 4 - PROGRESS: at 5.11% examples, 517916 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:49:02,422 : INFO : EPOCH 4 - PROGRESS: at 7.00% examples, 527833 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:49:03,426 : INFO : EPOCH 4 - PROGRESS: at 8.69% examples, 529567 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:49:04,467 : INFO : EPOCH 4 - PROGRESS: at 10.14% examples, 527438 words/s, in_qsize 17, out_qsize 2\n",
      "2018-09-04 14:49:05,475 : INFO : EPOCH 4 - PROGRESS: at 11.43% examples, 519408 words/s, in_qsize 18, out_qsize 3\n",
      "2018-09-04 14:49:06,480 : INFO : EPOCH 4 - PROGRESS: at 13.06% examples, 528626 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:49:07,510 : INFO : EPOCH 4 - PROGRESS: at 14.56% examples, 524936 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:49:08,517 : INFO : EPOCH 4 - PROGRESS: at 16.02% examples, 522086 words/s, in_qsize 20, out_qsize 4\n",
      "2018-09-04 14:49:09,520 : INFO : EPOCH 4 - PROGRESS: at 17.37% examples, 520440 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:49:10,556 : INFO : EPOCH 4 - PROGRESS: at 18.67% examples, 514470 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:49:11,606 : INFO : EPOCH 4 - PROGRESS: at 19.86% examples, 509351 words/s, in_qsize 16, out_qsize 3\n",
      "2018-09-04 14:49:12,618 : INFO : EPOCH 4 - PROGRESS: at 20.99% examples, 504935 words/s, in_qsize 20, out_qsize 3\n",
      "2018-09-04 14:49:13,637 : INFO : EPOCH 4 - PROGRESS: at 22.63% examples, 504044 words/s, in_qsize 19, out_qsize 4\n",
      "2018-09-04 14:49:14,676 : INFO : EPOCH 4 - PROGRESS: at 23.82% examples, 500992 words/s, in_qsize 19, out_qsize 9\n",
      "2018-09-04 14:49:15,700 : INFO : EPOCH 4 - PROGRESS: at 25.55% examples, 502946 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:49:16,701 : INFO : EPOCH 4 - PROGRESS: at 27.56% examples, 504677 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:49:17,706 : INFO : EPOCH 4 - PROGRESS: at 29.51% examples, 506755 words/s, in_qsize 18, out_qsize 0\n",
      "2018-09-04 14:49:18,707 : INFO : EPOCH 4 - PROGRESS: at 31.17% examples, 504274 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:49:19,709 : INFO : EPOCH 4 - PROGRESS: at 33.19% examples, 506856 words/s, in_qsize 17, out_qsize 0\n",
      "2018-09-04 14:49:20,724 : INFO : EPOCH 4 - PROGRESS: at 34.65% examples, 503621 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:49:21,745 : INFO : EPOCH 4 - PROGRESS: at 36.38% examples, 502581 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:49:22,774 : INFO : EPOCH 4 - PROGRESS: at 38.16% examples, 502340 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:49:23,800 : INFO : EPOCH 4 - PROGRESS: at 40.22% examples, 504733 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:49:24,838 : INFO : EPOCH 4 - PROGRESS: at 42.08% examples, 503479 words/s, in_qsize 20, out_qsize 2\n",
      "2018-09-04 14:49:25,856 : INFO : EPOCH 4 - PROGRESS: at 43.80% examples, 502659 words/s, in_qsize 20, out_qsize 2\n",
      "2018-09-04 14:49:26,985 : INFO : EPOCH 4 - PROGRESS: at 45.75% examples, 501469 words/s, in_qsize 17, out_qsize 7\n",
      "2018-09-04 14:49:27,988 : INFO : EPOCH 4 - PROGRESS: at 47.31% examples, 500010 words/s, in_qsize 16, out_qsize 5\n",
      "2018-09-04 14:49:28,991 : INFO : EPOCH 4 - PROGRESS: at 49.18% examples, 500594 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:49:30,000 : INFO : EPOCH 4 - PROGRESS: at 50.92% examples, 500784 words/s, in_qsize 18, out_qsize 0\n",
      "2018-09-04 14:49:31,004 : INFO : EPOCH 4 - PROGRESS: at 52.41% examples, 499215 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:49:32,021 : INFO : EPOCH 4 - PROGRESS: at 54.03% examples, 499144 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:49:33,023 : INFO : EPOCH 4 - PROGRESS: at 55.76% examples, 498491 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:49:34,037 : INFO : EPOCH 4 - PROGRESS: at 57.31% examples, 496900 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:49:35,049 : INFO : EPOCH 4 - PROGRESS: at 58.89% examples, 495779 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:49:36,057 : INFO : EPOCH 4 - PROGRESS: at 60.61% examples, 495809 words/s, in_qsize 20, out_qsize 4\n",
      "2018-09-04 14:49:37,104 : INFO : EPOCH 4 - PROGRESS: at 62.57% examples, 497154 words/s, in_qsize 20, out_qsize 7\n",
      "2018-09-04 14:49:38,130 : INFO : EPOCH 4 - PROGRESS: at 64.73% examples, 498480 words/s, in_qsize 20, out_qsize 2\n",
      "2018-09-04 14:49:39,132 : INFO : EPOCH 4 - PROGRESS: at 66.57% examples, 500281 words/s, in_qsize 17, out_qsize 2\n",
      "2018-09-04 14:49:40,143 : INFO : EPOCH 4 - PROGRESS: at 68.43% examples, 501262 words/s, in_qsize 17, out_qsize 2\n",
      "2018-09-04 14:49:41,154 : INFO : EPOCH 4 - PROGRESS: at 70.17% examples, 502179 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:49:42,156 : INFO : EPOCH 4 - PROGRESS: at 72.32% examples, 505541 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:49:43,158 : INFO : EPOCH 4 - PROGRESS: at 74.19% examples, 505780 words/s, in_qsize 19, out_qsize 2\n",
      "2018-09-04 14:49:44,173 : INFO : EPOCH 4 - PROGRESS: at 75.94% examples, 506702 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:49:45,184 : INFO : EPOCH 4 - PROGRESS: at 77.62% examples, 507256 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:49:46,221 : INFO : EPOCH 4 - PROGRESS: at 79.59% examples, 508910 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:49:47,224 : INFO : EPOCH 4 - PROGRESS: at 81.39% examples, 509945 words/s, in_qsize 20, out_qsize 1\n",
      "2018-09-04 14:49:48,240 : INFO : EPOCH 4 - PROGRESS: at 83.47% examples, 511828 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:49:49,259 : INFO : EPOCH 4 - PROGRESS: at 85.20% examples, 512471 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:49:50,276 : INFO : EPOCH 4 - PROGRESS: at 87.35% examples, 514207 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:49:51,300 : INFO : EPOCH 4 - PROGRESS: at 89.42% examples, 515188 words/s, in_qsize 20, out_qsize 4\n",
      "2018-09-04 14:49:52,307 : INFO : EPOCH 4 - PROGRESS: at 91.53% examples, 516689 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:49:53,413 : INFO : EPOCH 4 - PROGRESS: at 93.51% examples, 517037 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:49:54,424 : INFO : EPOCH 4 - PROGRESS: at 95.54% examples, 518028 words/s, in_qsize 18, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-04 14:49:55,448 : INFO : EPOCH 4 - PROGRESS: at 97.43% examples, 518559 words/s, in_qsize 16, out_qsize 3\n",
      "2018-09-04 14:49:56,449 : INFO : EPOCH 4 - PROGRESS: at 99.52% examples, 519945 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:49:56,551 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-09-04 14:49:56,566 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-09-04 14:49:56,567 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-09-04 14:49:56,568 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-09-04 14:49:56,570 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 14:49:56,571 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 14:49:56,583 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 14:49:56,593 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-04 14:49:56,607 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 14:49:56,612 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 14:49:56,613 : INFO : EPOCH - 4 : training on 41519355 raw words (30347864 effective words) took 58.3s, 520763 effective words/s\n",
      "2018-09-04 14:49:57,638 : INFO : EPOCH 5 - PROGRESS: at 1.76% examples, 549459 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:49:58,641 : INFO : EPOCH 5 - PROGRESS: at 3.67% examples, 565405 words/s, in_qsize 19, out_qsize 2\n",
      "2018-09-04 14:49:59,652 : INFO : EPOCH 5 - PROGRESS: at 5.72% examples, 581398 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:50:00,665 : INFO : EPOCH 5 - PROGRESS: at 7.60% examples, 581622 words/s, in_qsize 17, out_qsize 1\n",
      "2018-09-04 14:50:01,817 : INFO : EPOCH 5 - PROGRESS: at 9.21% examples, 553619 words/s, in_qsize 14, out_qsize 5\n",
      "2018-09-04 14:50:02,849 : INFO : EPOCH 5 - PROGRESS: at 10.84% examples, 559949 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:50:03,855 : INFO : EPOCH 5 - PROGRESS: at 12.24% examples, 557556 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:50:04,878 : INFO : EPOCH 5 - PROGRESS: at 14.12% examples, 565217 words/s, in_qsize 20, out_qsize 1\n",
      "2018-09-04 14:50:05,907 : INFO : EPOCH 5 - PROGRESS: at 15.69% examples, 559385 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:50:06,947 : INFO : EPOCH 5 - PROGRESS: at 17.01% examples, 549737 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:50:07,974 : INFO : EPOCH 5 - PROGRESS: at 18.41% examples, 545686 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:50:09,044 : INFO : EPOCH 5 - PROGRESS: at 19.61% examples, 536141 words/s, in_qsize 20, out_qsize 11\n",
      "2018-09-04 14:50:10,072 : INFO : EPOCH 5 - PROGRESS: at 21.17% examples, 541045 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:50:11,090 : INFO : EPOCH 5 - PROGRESS: at 22.62% examples, 532678 words/s, in_qsize 12, out_qsize 7\n",
      "2018-09-04 14:50:12,151 : INFO : EPOCH 5 - PROGRESS: at 23.98% examples, 531438 words/s, in_qsize 17, out_qsize 1\n",
      "2018-09-04 14:50:13,219 : INFO : EPOCH 5 - PROGRESS: at 25.71% examples, 529329 words/s, in_qsize 18, out_qsize 0\n",
      "2018-09-04 14:50:14,220 : INFO : EPOCH 5 - PROGRESS: at 27.67% examples, 528796 words/s, in_qsize 18, out_qsize 0\n",
      "2018-09-04 14:50:15,237 : INFO : EPOCH 5 - PROGRESS: at 29.54% examples, 527761 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:50:16,248 : INFO : EPOCH 5 - PROGRESS: at 31.52% examples, 528134 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:50:17,330 : INFO : EPOCH 5 - PROGRESS: at 33.22% examples, 523823 words/s, in_qsize 17, out_qsize 2\n",
      "2018-09-04 14:50:18,421 : INFO : EPOCH 5 - PROGRESS: at 34.95% examples, 521548 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:50:19,451 : INFO : EPOCH 5 - PROGRESS: at 36.63% examples, 518543 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:50:20,489 : INFO : EPOCH 5 - PROGRESS: at 38.32% examples, 516197 words/s, in_qsize 14, out_qsize 5\n",
      "2018-09-04 14:50:21,523 : INFO : EPOCH 5 - PROGRESS: at 40.29% examples, 517072 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:50:22,545 : INFO : EPOCH 5 - PROGRESS: at 42.28% examples, 517213 words/s, in_qsize 19, out_qsize 2\n",
      "2018-09-04 14:50:23,563 : INFO : EPOCH 5 - PROGRESS: at 44.06% examples, 516167 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:50:24,579 : INFO : EPOCH 5 - PROGRESS: at 46.09% examples, 517019 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:50:25,579 : INFO : EPOCH 5 - PROGRESS: at 47.77% examples, 516565 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:50:26,616 : INFO : EPOCH 5 - PROGRESS: at 49.55% examples, 515503 words/s, in_qsize 20, out_qsize 1\n",
      "2018-09-04 14:50:27,617 : INFO : EPOCH 5 - PROGRESS: at 51.33% examples, 515570 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:50:28,641 : INFO : EPOCH 5 - PROGRESS: at 52.99% examples, 515463 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:50:29,694 : INFO : EPOCH 5 - PROGRESS: at 54.69% examples, 514598 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:50:30,711 : INFO : EPOCH 5 - PROGRESS: at 56.45% examples, 513180 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:50:31,732 : INFO : EPOCH 5 - PROGRESS: at 58.32% examples, 513917 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:50:32,758 : INFO : EPOCH 5 - PROGRESS: at 60.02% examples, 512941 words/s, in_qsize 20, out_qsize 1\n",
      "2018-09-04 14:50:33,762 : INFO : EPOCH 5 - PROGRESS: at 61.99% examples, 514703 words/s, in_qsize 20, out_qsize 3\n",
      "2018-09-04 14:50:34,779 : INFO : EPOCH 5 - PROGRESS: at 64.38% examples, 517449 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:50:35,795 : INFO : EPOCH 5 - PROGRESS: at 66.00% examples, 516685 words/s, in_qsize 20, out_qsize 2\n",
      "2018-09-04 14:50:36,801 : INFO : EPOCH 5 - PROGRESS: at 68.05% examples, 518755 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:50:37,866 : INFO : EPOCH 5 - PROGRESS: at 69.69% examples, 517689 words/s, in_qsize 19, out_qsize 5\n",
      "2018-09-04 14:50:38,878 : INFO : EPOCH 5 - PROGRESS: at 71.46% examples, 518143 words/s, in_qsize 20, out_qsize 1\n",
      "2018-09-04 14:50:39,891 : INFO : EPOCH 5 - PROGRESS: at 73.50% examples, 519321 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:50:40,892 : INFO : EPOCH 5 - PROGRESS: at 75.29% examples, 519945 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:50:41,943 : INFO : EPOCH 5 - PROGRESS: at 76.96% examples, 519656 words/s, in_qsize 20, out_qsize 2\n",
      "2018-09-04 14:50:42,957 : INFO : EPOCH 5 - PROGRESS: at 78.82% examples, 520983 words/s, in_qsize 20, out_qsize 1\n",
      "2018-09-04 14:50:43,986 : INFO : EPOCH 5 - PROGRESS: at 80.74% examples, 522151 words/s, in_qsize 20, out_qsize 2\n",
      "2018-09-04 14:50:45,026 : INFO : EPOCH 5 - PROGRESS: at 82.82% examples, 523716 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:50:46,039 : INFO : EPOCH 5 - PROGRESS: at 84.64% examples, 524610 words/s, in_qsize 20, out_qsize 2\n",
      "2018-09-04 14:50:47,053 : INFO : EPOCH 5 - PROGRESS: at 86.80% examples, 526473 words/s, in_qsize 20, out_qsize 2\n",
      "2018-09-04 14:50:48,068 : INFO : EPOCH 5 - PROGRESS: at 88.96% examples, 527878 words/s, in_qsize 18, out_qsize 1\n",
      "2018-09-04 14:50:49,089 : INFO : EPOCH 5 - PROGRESS: at 90.85% examples, 527808 words/s, in_qsize 20, out_qsize 4\n",
      "2018-09-04 14:50:50,104 : INFO : EPOCH 5 - PROGRESS: at 93.04% examples, 529916 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:50:51,117 : INFO : EPOCH 5 - PROGRESS: at 94.97% examples, 530277 words/s, in_qsize 20, out_qsize 0\n",
      "2018-09-04 14:50:52,147 : INFO : EPOCH 5 - PROGRESS: at 97.11% examples, 531604 words/s, in_qsize 19, out_qsize 0\n",
      "2018-09-04 14:50:53,180 : INFO : EPOCH 5 - PROGRESS: at 99.07% examples, 531969 words/s, in_qsize 20, out_qsize 7\n",
      "2018-09-04 14:50:53,500 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2018-09-04 14:50:53,503 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2018-09-04 14:50:53,530 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-09-04 14:50:53,540 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-09-04 14:50:53,547 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-04 14:50:53,558 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-04 14:50:53,565 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-04 14:50:53,580 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-04 14:50:53,594 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-04 14:50:53,600 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-04 14:50:53,601 : INFO : EPOCH - 5 : training on 41519355 raw words (30347573 effective words) took 57.0s, 532645 effective words/s\n",
      "2018-09-04 14:50:53,602 : INFO : training on a 207596775 raw words (151746172 effective words) took 291.0s, 521423 effective words/s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ducoments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-415d44b376e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## build vocabulary and train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mducoments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# note: sg=0,1 (skip gram or cbow by default)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# note: hs=0,1 (hierarchical softmax or negative sampling by default)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ducoments' is not defined"
     ]
    }
   ],
   "source": [
    "## build vocabulary and train model\n",
    "model = gensim.models.Word2Vec(documents, size=128, window=10, min_count=2, workers=10)\n",
    "model.train(documents, total_examples=len(ducoments), epochs=10)\n",
    "# note: sg=0,1 (skip gram or cbow by default)\n",
    "# note: hs=0,1 (hierarchical softmax or negative sampling by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('queen', 0.9223220348358154),\n",
       " ('kingsize', 0.7811055183410645),\n",
       " ('double', 0.7755463123321533),\n",
       " ('twin', 0.7431386709213257),\n",
       " ('kingsized', 0.6692562103271484),\n",
       " ('queensize', 0.6658189296722412),\n",
       " ('dbl', 0.6539133787155151),\n",
       " ('rollaway', 0.6269456148147583),\n",
       " ('murphy', 0.618873119354248),\n",
       " ('bunk', 0.6067122220993042)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = 'king'\n",
    "model.wv.most_similar(positive=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=w1) == model.wv.similar_by_word(word=w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "queen_vector = model.wv['king'] - model.wv['man'] + model.wv['woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('king', 0.886066734790802),\n",
       " ('queen', 0.8435098528862),\n",
       " ('twin', 0.685721218585968),\n",
       " ('double', 0.6638386249542236),\n",
       " ('kingsize', 0.6603277921676636),\n",
       " ('rollaway', 0.5847185850143433),\n",
       " ('dbl', 0.5829118490219116),\n",
       " ('doubles', 0.5670033693313599),\n",
       " ('kingsized', 0.5556350946426392),\n",
       " ('queensize', 0.5528479814529419)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_vector(vector=queen_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('queen', 0.8155180811882019)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['woman', 'king'], negative=['man'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('courteous', 0.9206915497779846),\n",
       " ('curteous', 0.8683255910873413),\n",
       " ('cordial', 0.8621584177017212),\n",
       " ('curtious', 0.8323178291320801),\n",
       " ('friendly', 0.8258741497993469),\n",
       " ('freindly', 0.8191377520561218)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1 = ['polite']\n",
    "model.wv.most_similar(positive=w1, topn=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('germany', 0.75689697265625),\n",
       " ('canada', 0.7543196678161621),\n",
       " ('manchester', 0.7101644277572632),\n",
       " ('hawaii', 0.6989458799362183),\n",
       " ('england', 0.6869292855262756)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive='france', topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4099631743394041"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1='sunset', w2='cliff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = model.wv[vocab] # shape = [vocab_size, embedding_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, init='pca', n_iter=1000).fit_transform(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(tsne, index=vocab, columns=[\n",
    "    'comp'+str(i) for i in range(0, embedding_matrix.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_clustered_embeddings(embeddings,distance_threshold,sample_threshold):\n",
    "    ''' \n",
    "    Find only the closely clustered embeddings. \n",
    "    This gets rid of more sparsly distributed word embeddings and make the visualization clearer\n",
    "    This is useful for t-SNE visualization\n",
    "    \n",
    "    distance_threshold: maximum distance between two points to qualify as neighbors\n",
    "    sample_threshold: number of neighbors required to be considered a cluster\n",
    "    '''\n",
    "    \n",
    "    # calculate cosine similarity\n",
    "    cosine_sim = np.dot(embeddings,np.transpose(embeddings))\n",
    "    norm = np.dot(np.sum(embeddings**2,axis=1).reshape(-1,1),np.sum(np.transpose(embeddings)**2,axis=0).reshape(1,-1))\n",
    "    assert cosine_sim.shape == norm.shape\n",
    "    cosine_sim /= norm\n",
    "    \n",
    "    # make all the diagonal entries zero otherwise this will be picked as highest\n",
    "    np.fill_diagonal(cosine_sim, -1.0)\n",
    "    \n",
    "    argmax_cos_sim = np.argmax(cosine_sim, axis=1)\n",
    "    mod_cos_sim = cosine_sim\n",
    "    # find the maximums in a loop to count if there are more than n items above threshold\n",
    "    for _ in range(sample_threshold-1):\n",
    "        argmax_cos_sim = np.argmax(cosine_sim, axis=1)\n",
    "        mod_cos_sim[np.arange(mod_cos_sim.shape[0]),argmax_cos_sim] = -1\n",
    "    \n",
    "    max_cosine_sim = np.max(mod_cos_sim,axis=1)\n",
    "\n",
    "    return np.where(max_cosine_sim>distance_threshold)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 dev",
   "language": "python",
   "name": "py36_kernel_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
