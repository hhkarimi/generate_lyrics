{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## download songlyrics.zip from Kaggle, requires log in\n",
    "## https://www.kaggle.com/mousehead/songlyrics/downloads/songlyrics.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Ahe's My Kind Of Girl</td>\n",
       "      <td>Look at her face, it's a wonderful face  \\nAnd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Andante, Andante</td>\n",
       "      <td>Take it easy with me, please  \\nTouch me gentl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>As Good As New</td>\n",
       "      <td>I'll never know why I had to go  \\nWhy I had t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABBA</td>\n",
       "      <td>Bang-A-Boomerang</td>\n",
       "      <td>Making somebody happy is a question of give an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  artist                   song  \\\n",
       "0   ABBA  Ahe's My Kind Of Girl   \n",
       "1   ABBA       Andante, Andante   \n",
       "2   ABBA         As Good As New   \n",
       "3   ABBA                   Bang   \n",
       "4   ABBA       Bang-A-Boomerang   \n",
       "\n",
       "                                                text  \n",
       "0  Look at her face, it's a wonderful face  \\nAnd...  \n",
       "1  Take it easy with me, please  \\nTouch me gentl...  \n",
       "2  I'll never know why I had to go  \\nWhy I had t...  \n",
       "3  Making somebody happy is a question of give an...  \n",
       "4  Making somebody happy is a question of give an...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./data/kaggle_lyrics/songlyrics.zip')\n",
    "data.drop(columns=['link'], inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 152 songs set for Eric Clapton.\n",
      "There are 127 songs set for Jimi Hendrix.\n",
      "There are 188 songs set for Bob Dylan.\n",
      "There are 000 songs set for Muddy Waters.\n",
      "There are 041 songs set for Eagles.\n"
     ]
    }
   ],
   "source": [
    "## use kaggle data set on 57,650 songs (check if it has artists for text generation)\n",
    "\n",
    "artist_names = ['Eric Clapton', 'Jimi Hendrix', 'Bob Dylan', 'Muddy Waters', 'Eagles']\n",
    "for artist_name in artist_names:\n",
    "    print('There are {:03d} songs set for {}.'.format(\n",
    "        len(data[data['artist'].str.contains(artist_name)]), artist_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Look at her face, it's a wonderful face  . And it means something special to me  . Look at the way that she smiles when she sees me  . How lucky can one fellow be?  .   . She's just my kind of girl, she makes me feel fine  . Who could ever believe that she could be mine?  . She's just my kind of girl, without her I'm blue  . And if she ever leaves me what could I do, what could I do?  .   . And when we go for a walk in the park  . And she holds me and squeezes my hand  . We'll go on walking for hours and talking  . About all the things that we plan  .   . She's just my kind of girl, she makes me feel fine  . Who could ever believe that she could be mine?  . She's just my kind of girl, without her I'm blue  . And if she ever leaves me what could I do, what could I do?. . \""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'][0].replace('\\n', '. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 16s, sys: 1.65 s, total: 4min 18s\n",
      "Wall time: 4min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data['text'] = data['text'].apply(lambda text: word_tokenize(text.replace('\\n', '. ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-05 08:00:39,131 : INFO : collecting all words and their counts\n",
      "2018-09-05 08:00:39,132 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-09-05 08:00:39,648 : INFO : PROGRESS: at sentence #10000, processed 2843150 words, keeping 46342 word types\n",
      "2018-09-05 08:00:40,179 : INFO : PROGRESS: at sentence #20000, processed 5778998 words, keeping 69244 word types\n",
      "2018-09-05 08:00:40,692 : INFO : PROGRESS: at sentence #30000, processed 8605139 words, keeping 86151 word types\n",
      "2018-09-05 08:00:41,250 : INFO : PROGRESS: at sentence #40000, processed 11562789 words, keeping 101802 word types\n",
      "2018-09-05 08:00:41,841 : INFO : PROGRESS: at sentence #50000, processed 14573663 words, keeping 117756 word types\n",
      "2018-09-05 08:00:42,273 : INFO : collected 127646 word types from a corpus of 16830688 raw words and 57650 sentences\n",
      "2018-09-05 08:00:42,274 : INFO : Loading a fresh vocabulary\n",
      "2018-09-05 08:00:42,371 : INFO : effective_min_count=50 retains 8573 unique words (6% of original 127646, drops 119073)\n",
      "2018-09-05 08:00:42,372 : INFO : effective_min_count=50 leaves 16270931 word corpus (96% of original 16830688, drops 559757)\n",
      "2018-09-05 08:00:42,399 : INFO : deleting the raw counts dictionary of 127646 items\n",
      "2018-09-05 08:00:42,403 : INFO : sample=0.001 downsamples 51 most-common words\n",
      "2018-09-05 08:00:42,404 : INFO : downsampling leaves estimated 10570857 word corpus (65.0% of prior 16270931)\n",
      "2018-09-05 08:00:42,429 : INFO : estimated required memory for 8573 words and 128 dimensions: 13065252 bytes\n",
      "2018-09-05 08:00:42,430 : INFO : resetting layer weights\n",
      "2018-09-05 08:00:42,539 : INFO : training model with 6 workers on 8573 vocabulary and 128 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-09-05 08:00:43,548 : INFO : EPOCH 1 - PROGRESS: at 17.14% examples, 1764776 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:00:44,551 : INFO : EPOCH 1 - PROGRESS: at 33.55% examples, 1754905 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:00:45,557 : INFO : EPOCH 1 - PROGRESS: at 50.72% examples, 1750527 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:00:46,559 : INFO : EPOCH 1 - PROGRESS: at 67.02% examples, 1742546 words/s, in_qsize 12, out_qsize 1\n",
      "2018-09-05 08:00:47,562 : INFO : EPOCH 1 - PROGRESS: at 82.56% examples, 1734603 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:00:48,563 : INFO : EPOCH 1 - PROGRESS: at 97.98% examples, 1710815 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:00:48,732 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-05 08:00:48,734 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-05 08:00:48,739 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-05 08:00:48,740 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-05 08:00:48,746 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-05 08:00:48,747 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-05 08:00:48,748 : INFO : EPOCH - 1 : training on 16830688 raw words (10569224 effective words) took 6.2s, 1703328 effective words/s\n",
      "2018-09-05 08:00:49,758 : INFO : EPOCH 2 - PROGRESS: at 14.71% examples, 1493705 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:00:50,759 : INFO : EPOCH 2 - PROGRESS: at 28.50% examples, 1491389 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:00:51,762 : INFO : EPOCH 2 - PROGRESS: at 44.18% examples, 1536307 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:00:52,763 : INFO : EPOCH 2 - PROGRESS: at 60.12% examples, 1557705 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:00:53,766 : INFO : EPOCH 2 - PROGRESS: at 74.37% examples, 1570134 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:00:54,767 : INFO : EPOCH 2 - PROGRESS: at 89.86% examples, 1573089 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:00:55,438 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-05 08:00:55,440 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-05 08:00:55,445 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-05 08:00:55,446 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-05 08:00:55,451 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-05 08:00:55,452 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-05 08:00:55,453 : INFO : EPOCH - 2 : training on 16830688 raw words (10570460 effective words) took 6.7s, 1577374 effective words/s\n",
      "2018-09-05 08:00:56,460 : INFO : EPOCH 3 - PROGRESS: at 15.27% examples, 1568700 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:00:57,462 : INFO : EPOCH 3 - PROGRESS: at 30.36% examples, 1589457 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:00:58,464 : INFO : EPOCH 3 - PROGRESS: at 45.48% examples, 1582369 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:00:59,471 : INFO : EPOCH 3 - PROGRESS: at 60.64% examples, 1572459 words/s, in_qsize 9, out_qsize 2\n",
      "2018-09-05 08:01:00,476 : INFO : EPOCH 3 - PROGRESS: at 73.82% examples, 1557135 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:01,482 : INFO : EPOCH 3 - PROGRESS: at 89.03% examples, 1556746 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:02,230 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-05 08:01:02,236 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-05 08:01:02,237 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-05 08:01:02,243 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-05 08:01:02,244 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-05 08:01:02,248 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-05 08:01:02,249 : INFO : EPOCH - 3 : training on 16830688 raw words (10571328 effective words) took 6.8s, 1556721 effective words/s\n",
      "2018-09-05 08:01:03,260 : INFO : EPOCH 4 - PROGRESS: at 15.09% examples, 1540033 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:01:04,266 : INFO : EPOCH 4 - PROGRESS: at 28.12% examples, 1468652 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:05,269 : INFO : EPOCH 4 - PROGRESS: at 42.52% examples, 1478499 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:06,270 : INFO : EPOCH 4 - PROGRESS: at 56.41% examples, 1461534 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:07,276 : INFO : EPOCH 4 - PROGRESS: at 70.83% examples, 1480073 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:08,277 : INFO : EPOCH 4 - PROGRESS: at 85.03% examples, 1487204 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:09,284 : INFO : EPOCH 4 - PROGRESS: at 99.75% examples, 1497421 words/s, in_qsize 6, out_qsize 1\n",
      "2018-09-05 08:01:09,292 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-05 08:01:09,295 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-05 08:01:09,297 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-05 08:01:09,300 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-05 08:01:09,305 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-05 08:01:09,308 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-05 08:01:09,309 : INFO : EPOCH - 4 : training on 16830688 raw words (10570642 effective words) took 7.1s, 1498130 effective words/s\n",
      "2018-09-05 08:01:10,316 : INFO : EPOCH 5 - PROGRESS: at 15.09% examples, 1546995 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:01:11,321 : INFO : EPOCH 5 - PROGRESS: at 29.65% examples, 1552085 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:01:12,327 : INFO : EPOCH 5 - PROGRESS: at 44.78% examples, 1552783 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:13,327 : INFO : EPOCH 5 - PROGRESS: at 60.38% examples, 1564072 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:14,328 : INFO : EPOCH 5 - PROGRESS: at 74.07% examples, 1563863 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:15,335 : INFO : EPOCH 5 - PROGRESS: at 89.72% examples, 1568287 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:16,078 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-05 08:01:16,084 : INFO : worker thread finished; awaiting finish of 4 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-05 08:01:16,086 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-05 08:01:16,087 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-05 08:01:16,092 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-05 08:01:16,095 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-05 08:01:16,096 : INFO : EPOCH - 5 : training on 16830688 raw words (10571750 effective words) took 6.8s, 1558537 effective words/s\n",
      "2018-09-05 08:01:16,096 : INFO : training on a 84153440 raw words (52853404 effective words) took 33.6s, 1575003 effective words/s\n",
      "2018-09-05 08:01:16,099 : WARNING : Effective 'alpha' higher than previous training cycles\n",
      "2018-09-05 08:01:16,100 : INFO : training model with 6 workers on 8573 vocabulary and 128 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2018-09-05 08:01:17,106 : INFO : EPOCH 1 - PROGRESS: at 14.81% examples, 1513575 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:01:18,107 : INFO : EPOCH 1 - PROGRESS: at 28.75% examples, 1509852 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:01:19,113 : INFO : EPOCH 1 - PROGRESS: at 43.76% examples, 1524809 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:01:20,113 : INFO : EPOCH 1 - PROGRESS: at 58.91% examples, 1527629 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:01:21,119 : INFO : EPOCH 1 - PROGRESS: at 72.90% examples, 1538010 words/s, in_qsize 12, out_qsize 1\n",
      "2018-09-05 08:01:22,125 : INFO : EPOCH 1 - PROGRESS: at 88.23% examples, 1544191 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:01:22,913 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-05 08:01:22,917 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-05 08:01:22,920 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-05 08:01:22,927 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-05 08:01:22,928 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-05 08:01:22,931 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-05 08:01:22,931 : INFO : EPOCH - 1 : training on 16830688 raw words (10570515 effective words) took 6.8s, 1548475 effective words/s\n",
      "2018-09-05 08:01:23,940 : INFO : EPOCH 2 - PROGRESS: at 14.28% examples, 1454228 words/s, in_qsize 9, out_qsize 2\n",
      "2018-09-05 08:01:24,945 : INFO : EPOCH 2 - PROGRESS: at 27.82% examples, 1453026 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:01:25,946 : INFO : EPOCH 2 - PROGRESS: at 42.68% examples, 1488021 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:26,947 : INFO : EPOCH 2 - PROGRESS: at 58.18% examples, 1509373 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:27,953 : INFO : EPOCH 2 - PROGRESS: at 72.55% examples, 1523962 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:01:28,954 : INFO : EPOCH 2 - PROGRESS: at 87.59% examples, 1534569 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:01:29,773 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-05 08:01:29,780 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-05 08:01:29,781 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-05 08:01:29,786 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-05 08:01:29,787 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-05 08:01:29,792 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-05 08:01:29,793 : INFO : EPOCH - 2 : training on 16830688 raw words (10570046 effective words) took 6.9s, 1541407 effective words/s\n",
      "2018-09-05 08:01:30,805 : INFO : EPOCH 3 - PROGRESS: at 14.94% examples, 1524659 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:31,806 : INFO : EPOCH 3 - PROGRESS: at 29.52% examples, 1547561 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:32,807 : INFO : EPOCH 3 - PROGRESS: at 44.83% examples, 1558811 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:01:33,810 : INFO : EPOCH 3 - PROGRESS: at 60.24% examples, 1562860 words/s, in_qsize 9, out_qsize 2\n",
      "2018-09-05 08:01:34,811 : INFO : EPOCH 3 - PROGRESS: at 74.32% examples, 1569752 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:01:35,817 : INFO : EPOCH 3 - PROGRESS: at 89.96% examples, 1575458 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:36,490 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-05 08:01:36,492 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-05 08:01:36,497 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-05 08:01:36,498 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-05 08:01:36,503 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-05 08:01:36,504 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-05 08:01:36,505 : INFO : EPOCH - 3 : training on 16830688 raw words (10571182 effective words) took 6.7s, 1576537 effective words/s\n",
      "2018-09-05 08:01:37,510 : INFO : EPOCH 4 - PROGRESS: at 15.37% examples, 1580944 words/s, in_qsize 12, out_qsize 0\n",
      "2018-09-05 08:01:38,511 : INFO : EPOCH 4 - PROGRESS: at 30.09% examples, 1577795 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:39,517 : INFO : EPOCH 4 - PROGRESS: at 45.66% examples, 1586813 words/s, in_qsize 12, out_qsize 0\n",
      "2018-09-05 08:01:40,524 : INFO : EPOCH 4 - PROGRESS: at 61.27% examples, 1585434 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:41,528 : INFO : EPOCH 4 - PROGRESS: at 75.29% examples, 1588008 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:42,532 : INFO : EPOCH 4 - PROGRESS: at 90.77% examples, 1587129 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:43,138 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-05 08:01:43,140 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-05 08:01:43,143 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-05 08:01:43,144 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-05 08:01:43,150 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-05 08:01:43,151 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-05 08:01:43,152 : INFO : EPOCH - 4 : training on 16830688 raw words (10570936 effective words) took 6.6s, 1591238 effective words/s\n",
      "2018-09-05 08:01:44,158 : INFO : EPOCH 5 - PROGRESS: at 15.22% examples, 1561363 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:45,161 : INFO : EPOCH 5 - PROGRESS: at 30.29% examples, 1585568 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:46,169 : INFO : EPOCH 5 - PROGRESS: at 45.59% examples, 1582656 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:01:47,170 : INFO : EPOCH 5 - PROGRESS: at 60.44% examples, 1567461 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:01:48,180 : INFO : EPOCH 5 - PROGRESS: at 72.90% examples, 1535326 words/s, in_qsize 12, out_qsize 0\n",
      "2018-09-05 08:01:49,180 : INFO : EPOCH 5 - PROGRESS: at 87.59% examples, 1533415 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:01:50,049 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-05 08:01:50,051 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-05 08:01:50,053 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-05 08:01:50,054 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-05 08:01:50,061 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-05 08:01:50,062 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-05 08:01:50,062 : INFO : EPOCH - 5 : training on 16830688 raw words (10571779 effective words) took 6.9s, 1530722 effective words/s\n",
      "2018-09-05 08:01:51,070 : INFO : EPOCH 6 - PROGRESS: at 15.43% examples, 1589925 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:52,078 : INFO : EPOCH 6 - PROGRESS: at 30.37% examples, 1583740 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:01:53,087 : INFO : EPOCH 6 - PROGRESS: at 45.32% examples, 1568279 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:54,093 : INFO : EPOCH 6 - PROGRESS: at 60.91% examples, 1573347 words/s, in_qsize 11, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-05 08:01:55,098 : INFO : EPOCH 6 - PROGRESS: at 74.77% examples, 1573314 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:01:56,105 : INFO : EPOCH 6 - PROGRESS: at 90.29% examples, 1574928 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:56,740 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-05 08:01:56,742 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-05 08:01:56,745 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-05 08:01:56,746 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-05 08:01:56,749 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-05 08:01:56,753 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-05 08:01:56,753 : INFO : EPOCH - 6 : training on 16830688 raw words (10568488 effective words) took 6.7s, 1580695 effective words/s\n",
      "2018-09-05 08:01:57,761 : INFO : EPOCH 7 - PROGRESS: at 15.58% examples, 1601750 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:01:58,768 : INFO : EPOCH 7 - PROGRESS: at 30.67% examples, 1601981 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:01:59,775 : INFO : EPOCH 7 - PROGRESS: at 46.43% examples, 1610753 words/s, in_qsize 12, out_qsize 0\n",
      "2018-09-05 08:02:00,776 : INFO : EPOCH 7 - PROGRESS: at 62.26% examples, 1607900 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:02:01,783 : INFO : EPOCH 7 - PROGRESS: at 76.57% examples, 1614283 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:02:02,790 : INFO : EPOCH 7 - PROGRESS: at 92.46% examples, 1615643 words/s, in_qsize 9, out_qsize 2\n",
      "2018-09-05 08:02:03,274 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-05 08:02:03,276 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-05 08:02:03,279 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-05 08:02:03,280 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-05 08:02:03,287 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-05 08:02:03,288 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-05 08:02:03,289 : INFO : EPOCH - 7 : training on 16830688 raw words (10571436 effective words) took 6.5s, 1618460 effective words/s\n",
      "2018-09-05 08:02:04,293 : INFO : EPOCH 8 - PROGRESS: at 15.43% examples, 1594124 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:02:05,296 : INFO : EPOCH 8 - PROGRESS: at 30.70% examples, 1611126 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:02:06,297 : INFO : EPOCH 8 - PROGRESS: at 46.50% examples, 1620055 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:02:07,303 : INFO : EPOCH 8 - PROGRESS: at 62.90% examples, 1625313 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:02:08,305 : INFO : EPOCH 8 - PROGRESS: at 76.71% examples, 1621214 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:02:09,305 : INFO : EPOCH 8 - PROGRESS: at 92.85% examples, 1627687 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:02:09,775 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-05 08:02:09,781 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-05 08:02:09,781 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-05 08:02:09,787 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-05 08:02:09,789 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-05 08:02:09,791 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-05 08:02:09,792 : INFO : EPOCH - 8 : training on 16830688 raw words (10572144 effective words) took 6.5s, 1626730 effective words/s\n",
      "2018-09-05 08:02:10,801 : INFO : EPOCH 9 - PROGRESS: at 15.65% examples, 1604415 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:02:11,807 : INFO : EPOCH 9 - PROGRESS: at 31.08% examples, 1626268 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:02:12,811 : INFO : EPOCH 9 - PROGRESS: at 46.73% examples, 1619959 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:02:13,814 : INFO : EPOCH 9 - PROGRESS: at 62.90% examples, 1621593 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:02:14,819 : INFO : EPOCH 9 - PROGRESS: at 77.01% examples, 1622025 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:02:15,827 : INFO : EPOCH 9 - PROGRESS: at 92.84% examples, 1622150 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:02:16,291 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-05 08:02:16,297 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-05 08:02:16,298 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-05 08:02:16,303 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-05 08:02:16,306 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-05 08:02:16,307 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-05 08:02:16,308 : INFO : EPOCH - 9 : training on 16830688 raw words (10570384 effective words) took 6.5s, 1622931 effective words/s\n",
      "2018-09-05 08:02:17,316 : INFO : EPOCH 10 - PROGRESS: at 15.83% examples, 1624420 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:02:18,323 : INFO : EPOCH 10 - PROGRESS: at 31.13% examples, 1629247 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:02:19,327 : INFO : EPOCH 10 - PROGRESS: at 47.18% examples, 1634720 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:02:20,328 : INFO : EPOCH 10 - PROGRESS: at 62.80% examples, 1619609 words/s, in_qsize 11, out_qsize 0\n",
      "2018-09-05 08:02:21,332 : INFO : EPOCH 10 - PROGRESS: at 77.28% examples, 1628065 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:02:22,333 : INFO : EPOCH 10 - PROGRESS: at 93.31% examples, 1632116 words/s, in_qsize 10, out_qsize 1\n",
      "2018-09-05 08:02:22,761 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-09-05 08:02:22,767 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-09-05 08:02:22,769 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-09-05 08:02:22,774 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-09-05 08:02:22,775 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-09-05 08:02:22,779 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-09-05 08:02:22,780 : INFO : EPOCH - 10 : training on 16830688 raw words (10569539 effective words) took 6.5s, 1634003 effective words/s\n",
      "2018-09-05 08:02:22,781 : INFO : training on a 168306880 raw words (105706449 effective words) took 66.7s, 1585225 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 48s, sys: 4.73 s, total: 6min 53s\n",
      "Wall time: 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## generate embeddings\n",
    "## build vocabulary and train model\n",
    "model = Word2Vec(data['text'].tolist(), size=128, window=10, min_count=50, workers=6, sg=0, hs=0)\n",
    "model.train(data['text'].tolist(), total_examples=len(data['text']), epochs=10)\n",
    "# note: sg=0,1 (skip gram or cbow by default)\n",
    "# note: hs=0,1 (hierarchical softmax or negative sampling by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-09-05 08:02:22,790 : INFO : precomputing L2-norms of word weight vectors\n",
      "/Users/hkarimi/venvs/py36_dev/lib/python3.6/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('woman', 0.5012178421020508),\n",
       " ('Cold', 0.48644325137138367),\n",
       " ('hunter', 0.4433850944042206),\n",
       " ('heartless', 0.43375563621520996),\n",
       " ('Dom', 0.433209091424942)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['man', 'cold'], negative=[], topn=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8573\n"
     ]
    }
   ],
   "source": [
    "## build vocab and embedding matrix\n",
    "vocab = list(model.wv.vocab)\n",
    "embedding_matrix = model.wv[vocab] # shape = [vocab_size, embedding_size]\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clustered_embeddings(embeddings, distance_threshold, sample_threshold):\n",
    "    ''' \n",
    "    Find only the closely clustered embeddings. \n",
    "    This gets rid of more sparsly distributed word embeddings and make the visualization clearer\n",
    "    This is useful for t-SNE visualization\n",
    "    \n",
    "    distance_threshold: maximum distance between two points to qualify as neighbors\n",
    "    sample_threshold: number of neighbors required to be considered a cluster\n",
    "    '''\n",
    "    \n",
    "    # calculate cosine similarity\n",
    "    cosine_sim = np.dot(embeddings,np.transpose(embeddings))\n",
    "    norm = np.dot(np.sum(embeddings**2,axis=1).reshape(-1,1),np.sum(np.transpose(embeddings)**2,axis=0).reshape(1,-1))\n",
    "    assert cosine_sim.shape == norm.shape\n",
    "    cosine_sim /= norm\n",
    "    \n",
    "    # make all the diagonal entries zero otherwise this will be picked as highest\n",
    "    np.fill_diagonal(cosine_sim, -1.0)\n",
    "    \n",
    "    argmax_cos_sim = np.argmax(cosine_sim, axis=1)\n",
    "    mod_cos_sim = cosine_sim\n",
    "    # find the maximums in a loop to count if there are more than n items above threshold\n",
    "    for _ in range(sample_threshold-1):\n",
    "        argmax_cos_sim = np.argmax(cosine_sim, axis=1)\n",
    "        mod_cos_sim[np.arange(mod_cos_sim.shape[0]),argmax_cos_sim] = -1\n",
    "    \n",
    "    max_cosine_sim = np.max(mod_cos_sim,axis=1)\n",
    "\n",
    "    return np.where(max_cosine_sim>distance_threshold)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Computing 121 nearest neighbors...\n",
      "[t-SNE] Indexed 8573 samples in 0.038s...\n",
      "[t-SNE] Computed neighbors for 8573 samples in 18.252s...\n",
      "[t-SNE] Computed conditional probabilities for sample 1000 / 8573\n",
      "[t-SNE] Computed conditional probabilities for sample 2000 / 8573\n",
      "[t-SNE] Computed conditional probabilities for sample 3000 / 8573\n",
      "[t-SNE] Computed conditional probabilities for sample 4000 / 8573\n",
      "[t-SNE] Computed conditional probabilities for sample 5000 / 8573\n",
      "[t-SNE] Computed conditional probabilities for sample 6000 / 8573\n",
      "[t-SNE] Computed conditional probabilities for sample 7000 / 8573\n",
      "[t-SNE] Computed conditional probabilities for sample 8000 / 8573\n",
      "[t-SNE] Computed conditional probabilities for sample 8573 / 8573\n",
      "[t-SNE] Mean sigma: 2.946026\n",
      "[t-SNE] KL divergence after 250 iterations with early exaggeration: 88.207901\n",
      "[t-SNE] Error after 2500 iterations: 3.016892\n",
      "CPU times: user 13min 49s, sys: 52.5 s, total: 14min 41s\n",
      "Wall time: 14min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "## tsne and visualize\n",
    "num_embeddings = len(vocab)\n",
    "selected_embeddings = embedding_matrix[:num_embeddings,:]\n",
    "\n",
    "tsne = TSNE(perplexity=40, n_components=2, init='pca', n_iter=2500, verbose=1).fit_transform(selected_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning the T-SNE embeddings\n",
      "Out of  8573  samples,  372  samples were selected by pruning\n"
     ]
    }
   ],
   "source": [
    "print('Pruning the T-SNE embeddings')\n",
    "# prune the embeddings by getting ones only more than n-many sample above the similarity threshold\n",
    "# this unclutters the visualization\n",
    "selected_ids = find_clustered_embeddings(selected_embeddings, 0.01, 1)\n",
    "tsne_plot = tsne[selected_ids,:]\n",
    "\n",
    "print('Out of ', num_embeddings, ' samples, ', selected_ids.shape[0],' samples were selected by pruning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see plotting code here: \n",
    "# https://github.com/PacktPublishing/Natural-Language-Processing-with-TensorFlow/blob/master/ch3/ch3_word2vec.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py36_dev",
   "language": "python",
   "name": "py36_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
