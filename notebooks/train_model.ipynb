{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## based on:\n",
    "## https://github.com/rasbt/python-machine-learning-book-2nd-edition/blob/master/code/ch16/ch16.ipynb\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## load embedding matrix and vocabulary\n",
    "path = './data/'\n",
    "int2token = np.load(path + 'vocab.npy')\n",
    "embedding_matrix = np.load(path + 'embedding_matrix.npy') # shape = [vocab_size, embedding_size]\n",
    "\n",
    "# create dictionary{word: int}\n",
    "token2int = {token: i for i, token in enumerate(int2token)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eagles</td>\n",
       "      <td>After The Thrill Is Gone</td>\n",
       "      <td>[[, Verse, ], Same, dances, in, the, same, old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Eagles</td>\n",
       "      <td>All She Wants To Do Is Dance</td>\n",
       "      <td>[They, 're, pickin, ', up, the, prisoners, And...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eagles</td>\n",
       "      <td>Already Gone</td>\n",
       "      <td>[[, Verse, 1, ], Well, ,, I, heard, some, peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eagles</td>\n",
       "      <td>Best of My Love</td>\n",
       "      <td>[[, Verse, 1, ], Every, night, I, 'm, lying, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eagles</td>\n",
       "      <td>Bitter Creek</td>\n",
       "      <td>[Once, I, was, young, and, so, unsure, I, 'd, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist                          song  \\\n",
       "0  Eagles      After The Thrill Is Gone   \n",
       "1  Eagles  All She Wants To Do Is Dance   \n",
       "2  Eagles                  Already Gone   \n",
       "3  Eagles               Best of My Love   \n",
       "4  Eagles                  Bitter Creek   \n",
       "\n",
       "                                              lyrics  \n",
       "0  [[, Verse, ], Same, dances, in, the, same, old...  \n",
       "1  [They, 're, pickin, ', up, the, prisoners, And...  \n",
       "2  [[, Verse, 1, ], Well, ,, I, heard, some, peop...  \n",
       "3  [[, Verse, 1, ], Every, night, I, 'm, lying, i...  \n",
       "4  [Once, I, was, young, and, so, unsure, I, 'd, ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load and tokenize lyrics\n",
    "with open('./data/lyrics_by_artist/Eagles.json') as f:\n",
    "    tmp = json.load(f)\n",
    "data = pd.DataFrame(columns=['artist', 'song', 'lyrics'])\n",
    "for i in range(0, len(tmp['artists'][0]['songs'])):\n",
    "    data = data.append({'artist': tmp['artists'][0]['artist'],\n",
    "                        'song': tmp['artists'][0]['songs'][i]['title'],\n",
    "                         'lyrics': tmp['artists'][0]['songs'][i]['lyrics']},\n",
    "                         ignore_index=True)\n",
    "    \n",
    "data['lyrics'] = data['lyrics'].apply(lambda text: word_tokenize(text))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = Counter()\n",
    "for i, song in enumerate(data['lyrics']):\n",
    "    counts.update(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 909), (',', 856), ('I', 696), ('you', 634), ('to', 559)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.2 ms, sys: 17 Âµs, total: 8.22 ms\n",
      "Wall time: 8.19 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# convert words/tokens to integers from dictionary\n",
    "def tokens_to_int(tokens):\n",
    "    mapped_tokens = []\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            mapped_tokens.append(token2int[token])\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return mapped_tokens\n",
    "data['lyrics'] = data['lyrics'].apply(tokens_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## contatenate words together\n",
    "## https://github.com/hunkim/word-rnn-tensorflow/tree/master/data/tinyshakespeare/input.txt\n",
    "tmp = []\n",
    "count = 0\n",
    "for lyrics in data['lyrics']:\n",
    "    count = count + len(lyrics)\n",
    "    tmp.extend(lyrics)\n",
    "data = np.array(tmp)\n",
    "assert len(data) == count\n",
    "del tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\n",
    "#     'mean num_tokens: {:.1f}'.format(data['lyrics'].apply(lambda x: len(x)).mean()),\n",
    "#     '\\nmin num_tokens: {:d}'.format(data['lyrics'].apply(lambda x: len(x)).min()),\n",
    "#     '\\nmax num_tokens: {:d}'.format(data['lyrics'].apply(lambda x: len(x)).max())\n",
    "#     )\n",
    "\n",
    "# # pad with token '.'\n",
    "# mean_lyrics_length = data['lyrics'].apply(lambda x: len(x)).mean()\n",
    "# max_lyrics_length = data['lyrics'].apply(lambda x: len(x)).max()\n",
    "# sequence_length = int(np.mean([mean_lyrics_length, max_lyrics_length]))\n",
    "# sequences = np.full(shape=(len(data), sequence_length), fill_value=token2int['.'], dtype=int)\n",
    "# for i, row in enumerate(data['lyrics'].values):\n",
    "#     sequences[i, -len(row):] = row[-sequence_length:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train: [ 848 2825  849 3741 6986   56   16  561  795 1195  359]\n",
      "y_train: [2825  849 3741 6986   56   16  561  795 1195  359]\n",
      "\n",
      "Stats:\n",
      "Percent of data lost: 2.81%\n",
      "mini_seq_len = 256\n",
      "\n",
      "Beginning of Input:\n",
      " [ Verse ] Same dances in the same old shoes Some habits that you just ca n't lose There's no telling what a man might use After the thrill is gone The flame rises but it soon descends Empty pages and a frozen pen You're not quite lovers\n"
     ]
    }
   ],
   "source": [
    "## split into batch_size batches, each batch with subsequences of size mini_seq_len\n",
    "## so number of subsequences per batch is len(sequence)/(batch_size * mini_seq_len)\n",
    "\n",
    "def reshape_data(sequence, batch_size, mini_seq_len):\n",
    "    tot_batch_length = batch_size * mini_seq_len\n",
    "    num_seq_per_batch = int(len(sequence) / tot_batch_length)\n",
    "    if num_seq_per_batch*tot_batch_length + 1 > len(sequence):\n",
    "        num_seq_per_batch = num_seq_per_batch - 1\n",
    "    ## Truncate the sequence at the end to get rid of \n",
    "    ## remaining charcaters that do not make a full batch\n",
    "    x = sequence[0 : num_seq_per_batch*tot_batch_length]\n",
    "    y = sequence[1 : num_seq_per_batch*tot_batch_length + 1]\n",
    "    ## Split x & y into a list batches of sequences: \n",
    "    x_batch_splits = np.split(x, batch_size)\n",
    "    y_batch_splits = np.split(y, batch_size)\n",
    "    ## Stack the batches together\n",
    "    ## batch_size x mini_batch_length\n",
    "    x = np.stack(x_batch_splits)\n",
    "    y = np.stack(y_batch_splits)\n",
    "    \n",
    "    return x, y\n",
    "\n",
    "\n",
    "# set data shape parameters\n",
    "batch_size = 16\n",
    "mini_seq_len = 256\n",
    "\n",
    "# reshape and check\n",
    "x_train, y_train = reshape_data(data, batch_size=batch_size, mini_seq_len=mini_seq_len)\n",
    "print('x_train:', x_train[0, :11])\n",
    "print('y_train:', y_train[0, :10])\n",
    "\n",
    "# interesting stats\n",
    "mini_seq_per_batch = int( len(data) / (batch_size*mini_seq_len) )\n",
    "total_tokens_kept = mini_seq_per_batch * mini_seq_len * batch_size\n",
    "num_seq_per_batch = mini_seq_per_batch * mini_seq_len\n",
    "print('\\nStats:')\n",
    "print('Percent of data lost: {:.2f}%'.format(100*( len(data)-len(x_train.flatten()) )  / len(data)))\n",
    "print('mini_seq_len = {}'.format(mini_seq_len))\n",
    "\n",
    "# print data pull sample\n",
    "sample = ' '.join(int2token[i] for i in x_train[0, :50])\n",
    "print('\\nBeginning of Input:\\n', sample.replace(\" '\", \"'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## set target to predict the next word in the sequence, so y is x offset by 1 position\n",
    "# train_percentage = 0.8\n",
    "# train_length = int(train_percentage*len(data))\n",
    "\n",
    "# # split data, offset target by 1 position, drop the last word for inputs\n",
    "# X_train = sequences[:train_length, :]\n",
    "# y_train = X_train[:, 1:]\n",
    "# X_train = X_train[:, :-1]\n",
    "\n",
    "# X_test = sequences[train_length:, :]\n",
    "# y_test = np.zeros(X_test.shape, dtype=int)\n",
    "# y_test[:, :-1] = X_test[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('X_train:\\n', X_train[:3,:])\n",
    "# print('y_train:\\n', y_train[:3,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## build LSTM model\n",
    "\n",
    "class LyricsGeneratorNN(object):\n",
    "    def __init__(self, token2int, int2token, embedding_matrix, mini_seq_len=100, batch_size=16,\n",
    "                 num_nodes=128, num_layers=1, learning_rate=0.001, keep_prob=0.5, grad_clip=5, \n",
    "                 sampling=False):\n",
    "        self.num_tokens = len(token2int)\n",
    "        self.token2int = token2int\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "        self.mini_seq_len = mini_seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_layers = num_layers\n",
    "        self.learning_rate = learning_rate\n",
    "        self.keep_prob = keep_prob\n",
    "        self.grad_clip = grad_clip\n",
    "        \n",
    "        self.g = tf.Graph()\n",
    "        with self.g.as_default():\n",
    "            tf.set_random_seed(21)\n",
    "            \n",
    "            self.build(sampling=sampling)\n",
    "            self.saver = tf.train.Saver()\n",
    "            self.init_op = tf.global_variables_initializer()\n",
    "            \n",
    "            \n",
    "    def build(self, sampling):\n",
    "        if sampling == True:\n",
    "            batch_size, mini_seq_len = 1, 1\n",
    "        else:\n",
    "            batch_size = self.batch_size\n",
    "            mini_seq_len = self.mini_seq_len\n",
    "            \n",
    "        tf_x = tf.placeholder(tf.int32, shape=[batch_size, mini_seq_len], name='tf_x')\n",
    "        tf_y = tf.placeholder(tf.int32, shape=[batch_size, mini_seq_len], name='tf_y')\n",
    "        tf_keep_prob = tf.placeholder(tf.float32, name='tf_keep_prob')\n",
    "        \n",
    "        # load the embedding layer\n",
    "        embedding = tf.constant(self.embedding_matrix, name='embedding')\n",
    "        embed_x = tf.nn.embedding_lookup(embedding, tf_x, name='embedded_x')\n",
    "        \n",
    "        # one-hot encoding\n",
    "        x_onehot = tf.one_hot(tf_x, depth=self.num_tokens)\n",
    "        y_onehot = tf.one_hot(tf_y, depth=self.num_tokens)\n",
    "        \n",
    "        # build the multi-layer LSTM cells\n",
    "        cells = tf.contrib.rnn.MultiRNNCell(\n",
    "            [tf.contrib.rnn.DropoutWrapper(\n",
    "                tf.contrib.rnn.BasicLSTMCell(self.num_nodes), output_keep_prob=tf_keep_prob)\n",
    "            for _ in range(0, self.num_layers)])\n",
    "        \n",
    "        # set initial state\n",
    "        self.initial_state = cells.zero_state(batch_size, tf.float32)\n",
    "        \n",
    "        # run each sequence step through the RNN\n",
    "#         lstm_outputs, self.final_state = tf.nn.dynamic_rnn(\n",
    "#             cells, x_onehot, initial_state=self.initial_state)\n",
    "\n",
    "        lstm_outputs, self.final_state = tf.nn.dynamic_rnn(\n",
    "            cells, embed_x, initial_state=self.initial_state)\n",
    "        print('lstm_outputs:', lstm_outputs)\n",
    "        \n",
    "        seq_output_reshaped = tf.reshape(lstm_outputs, shape=[-1, self.num_nodes],\n",
    "                                         name='seq_output_reshaped')\n",
    "        \n",
    "        logits = tf.layers.dense(inputs=seq_output_reshaped, units=self.num_tokens,\n",
    "                                 activation=None, name='logits')\n",
    "        \n",
    "        proba = tf.nn.softmax(logits, name='probabilities')\n",
    "        print(proba)\n",
    "        \n",
    "        y_reshaped = tf.reshape(y_onehot, shape=[-1, self.num_tokens], name='y_reshaped')\n",
    "        \n",
    "        try:\n",
    "            cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                logits=logits, labels=y_reshaped), name='cost')\n",
    "        except AttributeError:\n",
    "            cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "                logits=logits, labels=y_reshaped), name='cost')\n",
    "        \n",
    "        # gradient clipping to avoid exploding gradients\n",
    "        tvars = tf.trainable_variables()\n",
    "        grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), self.grad_clip)\n",
    "        optimizer = tf.train.AdamOptimizer(self.learning_rate)\n",
    "        train_op = optimizer.apply_gradients(zip(grads, tvars), name='train_op')\n",
    "        \n",
    "        \n",
    "    def train(self, x_train, y_train, num_epochs, ckpt_dir='./model/'):\n",
    "        # set up checkpoint for saving\n",
    "        if not os.path.exists(ckpt_dir):\n",
    "            os.mkdir(ckpt_dir)\n",
    "            \n",
    "        with tf.Session(graph=self.g) as session:\n",
    "            session.run(self.init_op)\n",
    "            \n",
    "            mini_seq_per_batch = int(x_train.shape[1]/self.mini_seq_len)\n",
    "            iterations = mini_seq_per_batch * num_epochs\n",
    "            for epoch in range(0, num_epochs):\n",
    "                \n",
    "                # train network\n",
    "                new_state = session.run(self.initial_state)\n",
    "                loss = 0\n",
    "                \n",
    "                # minibatch operator\n",
    "                generated_batch = self.create_batch_generator(x_train, y_train, self.mini_seq_len)\n",
    "                for b, (x_batch, y_batch) in enumerate(generated_batch, 1):\n",
    "                    iteration = epoch*mini_seq_per_batch + b\n",
    "                    \n",
    "                    feed = {'tf_x:0': x_batch, 'tf_y:0': y_batch, \n",
    "                            'tf_keep_prob:0': self.keep_prob, self.initial_state: new_state}\n",
    "                    batch_cost, _, new_state = session.run(\n",
    "                        ['cost:0', 'train_op', self.final_state], feed_dict=feed)\n",
    "                    \n",
    "                    if iteration % 10 == 0:\n",
    "                        print('Epoch {:d}/{:d} Iteration {:d} | Training loss: {:.4f}'.format(\n",
    "                            epoch+1, num_epochs, iteration, batch_cost))\n",
    "                        \n",
    "                ## save trained model\n",
    "                self.saver.save(session, os.path.join(\n",
    "                    ckpt_dir, 'lyrics_generator.ckpt'))\n",
    "\n",
    "\n",
    "    def create_batch_generator(self, x, y, mini_seq_len):\n",
    "        batch_size, tokens_per_batch = x.shape\n",
    "        mini_seq_per_batch = int(tokens_per_batch/mini_seq_len)\n",
    "        for b in range(0, mini_seq_per_batch):\n",
    "            yield(x[:, b*mini_seq_len:(b+1)*mini_seq_len],\n",
    "                  y[:, b*mini_seq_len:(b+1)*mini_seq_len])\n",
    "    \n",
    "    \n",
    "    def sample(self, output_length, ckpt_dir, starter_tokens=[\"The\", \"rain\"], beam_search=False):\n",
    "        observed_seq = [token for token in starter_tokens]\n",
    "        with tf.Session(graph=self.g) as session:\n",
    "            self.saver.restore(session, tf.train.latest_checkpoint(ckpt_dir))\n",
    "            \n",
    "            # TODO: add beam_search\n",
    "            if beam_search:\n",
    "                print('TODO: come back again')\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "            # 1: run the model using starter tokens\n",
    "            new_state = session.run(self.initial_state)\n",
    "            for token in starter_tokens:\n",
    "                x = np.zeros((1,1))\n",
    "                x[0, 0] = token2int[token]\n",
    "                \n",
    "                feed = {'tf_x:0': x, 'tf_keep_prob:0': 1.0, self.initial_state: new_state}\n",
    "                proba, new_state = session.run(\n",
    "                    ['probabilities:0', self.final_state], feed_dict=feed)\n",
    "                \n",
    "            token_id = self.get_top_token(proba, len(int2token))\n",
    "            observed_seq.append(int2token[token_id])\n",
    "                \n",
    "            # 2: run model using updated observed_seq\n",
    "            for i in range(0, output_length):\n",
    "                x[0, 0] = token_id\n",
    "                feed = {'tf_x:0': x, 'tf_keep_prob:0': 1.0,\n",
    "                        self.initial_state: new_state}\n",
    "                proba, new_state = session.run(\n",
    "                    ['probabilities:0', self.final_state], feed_dict=feed)\n",
    "                \n",
    "                token_id = self.get_top_token(proba, len(int2token))\n",
    "                observed_seq.append(int2token[token_id])\n",
    "                \n",
    "            return ' '.join(observed_seq)\n",
    "        \n",
    "        \n",
    "    def get_top_token(self, probas, token_size, top_n=5):\n",
    "        p = np.squeeze(probas)\n",
    "        p[np.argsort(p)[:-top_n]] = 0.0\n",
    "        p = p / np.sum(p)\n",
    "        token_id = np.random.choice(token_size, 1, p=p)[0]\n",
    "        return token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lstm_outputs: Tensor(\"rnn/transpose:0\", shape=(16, 256, 128), dtype=float32)\n",
      "Tensor(\"probabilities:0\", shape=(4096, 24189), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# set data shape parameters\n",
    "batch_size = 16\n",
    "mini_seq_len = 256\n",
    "\n",
    "# reshape and check\n",
    "x_train, y_train = reshape_data(data, batch_size=batch_size, mini_seq_len=mini_seq_len)\n",
    "\n",
    "mini_seq_per_batch = int( len(data) / (batch_size*mini_seq_len) )\n",
    "total_tokens_kept = mini_seq_per_batch * mini_seq_len * batch_size\n",
    "num_seq_per_batch = mini_seq_per_batch * mini_seq_len\n",
    "\n",
    "lstm = LyricsGeneratorNN(token2int, int2token, embedding_matrix, mini_seq_len=mini_seq_len,\n",
    "                         batch_size=batch_size, num_nodes=128, num_layers=1, sampling=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lstm.train(x_train, y_train, num_epochs=100, ckpt_dir='./model-10/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## rebuild lstm with input tensor shape (1,1) for sampling/generating\n",
    "try: del lstm\n",
    "except NameError: pass\n",
    "\n",
    "np.random.seed(21)\n",
    "lstm = LyricsGeneratorNN(token2int, int2token, embedding_matrix, mini_seq_len=mini_seq_len,\n",
    "                         batch_size=batch_size, num_nodes=128, num_layers=1, sampling=True)\n",
    "print(lstm.sample(ckpt_dir='./model-10/', output_length=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 dev",
   "language": "python",
   "name": "py36_kernel_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
